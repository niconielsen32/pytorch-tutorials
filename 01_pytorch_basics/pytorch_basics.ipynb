{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Basics\n",
    "\n",
    "This notebook covers the fundamental concepts of PyTorch, including tensors, operations, and computational graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check PyTorch version\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tensors\n",
    "\n",
    "Tensors are the fundamental data structure in PyTorch, similar to NumPy arrays but with additional capabilities like GPU acceleration and automatic differentiation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Creating Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor from a Python list\n",
    "x = torch.tensor([1, 2, 3, 4])\n",
    "print(f\"Tensor from list: {x}\")\n",
    "\n",
    "# Create a 2D tensor (matrix)\n",
    "matrix = torch.tensor([[1, 2], [3, 4]])\n",
    "print(f\"\\nMatrix:\\n{matrix}\")\n",
    "\n",
    "# Create tensors with specific data types\n",
    "float_tensor = torch.tensor([1.0, 2.0, 3.0], dtype=torch.float32)\n",
    "int_tensor = torch.tensor([1, 2, 3], dtype=torch.int64)\n",
    "print(f\"\\nFloat tensor: {float_tensor}\")\n",
    "print(f\"Integer tensor: {int_tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tensors with specific shapes\n",
    "zeros = torch.zeros(3, 4)\n",
    "ones = torch.ones(2, 3)\n",
    "rand = torch.rand(2, 2)  # Uniform distribution [0, 1)\n",
    "randn = torch.randn(2, 2)  # Normal distribution (mean=0, std=1)\n",
    "\n",
    "print(f\"Zeros tensor:\\n{zeros}\")\n",
    "print(f\"\\nOnes tensor:\\n{ones}\")\n",
    "print(f\"\\nRandom uniform tensor:\\n{rand}\")\n",
    "print(f\"\\nRandom normal tensor:\\n{randn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor with a specific range\n",
    "range_tensor = torch.arange(0, 10, step=1)\n",
    "linspace = torch.linspace(0, 1, steps=5)\n",
    "print(f\"Range tensor: {range_tensor}\")\n",
    "print(f\"Linspace tensor: {linspace}\")\n",
    "\n",
    "# Create an identity matrix\n",
    "eye = torch.eye(3)\n",
    "print(f\"\\nIdentity matrix:\\n{eye}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Tensor Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(3, 4, 5)\n",
    "\n",
    "print(f\"Tensor shape: {x.shape}\")\n",
    "print(f\"Tensor size: {x.size()}\")\n",
    "print(f\"Number of dimensions: {x.dim()}\")\n",
    "print(f\"Data type: {x.dtype}\")\n",
    "print(f\"Device: {x.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Tensor Indexing and Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(f\"Original tensor:\\n{x}\")\n",
    "\n",
    "# Indexing\n",
    "print(f\"\\nIndexing:\")\n",
    "print(f\"x[0, 0] = {x[0, 0]}\")\n",
    "print(f\"x[1, 2] = {x[1, 2]}\")\n",
    "\n",
    "# Slicing\n",
    "print(f\"\\nSlicing:\")\n",
    "print(f\"First column:\\n{x[:, 0]}\")\n",
    "print(f\"Second row:\\n{x[1, :]}\")\n",
    "print(f\"Sub-matrix (top-right 2x2):\\n{x[0:2, 1:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced indexing\n",
    "indices = torch.tensor([0, 2])\n",
    "print(f\"Advanced indexing with indices [0, 2]:\\n{x[indices]}\")\n",
    "\n",
    "# Boolean indexing\n",
    "mask = x > 5\n",
    "print(f\"\\nBoolean mask (x > 5):\\n{mask}\")\n",
    "print(f\"Elements where x > 5:\\n{x[mask]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tensor Operations\n",
    "\n",
    "PyTorch provides a wide range of operations for manipulating tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Arithmetic Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([4, 5, 6])\n",
    "\n",
    "print(f\"a = {a}\")\n",
    "print(f\"b = {b}\")\n",
    "\n",
    "# Addition\n",
    "print(f\"a + b = {a + b}\")\n",
    "print(f\"torch.add(a, b) = {torch.add(a, b)}\")\n",
    "\n",
    "# Subtraction\n",
    "print(f\"a - b = {a - b}\")\n",
    "print(f\"torch.sub(a, b) = {torch.sub(a, b)}\")\n",
    "\n",
    "# Multiplication (element-wise)\n",
    "print(f\"a * b = {a * b}\")\n",
    "print(f\"torch.mul(a, b) = {torch.mul(a, b)}\")\n",
    "\n",
    "# Division (element-wise)\n",
    "print(f\"a / b = {a / b}\")\n",
    "print(f\"torch.div(a, b) = {torch.div(a, b)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In-place operations (modifies the tensor)\n",
    "c = torch.tensor([1, 2, 3])\n",
    "print(f\"Original c = {c}\")\n",
    "\n",
    "c.add_(b)  # Note the underscore suffix for in-place operations\n",
    "print(f\"After c.add_(b), c = {c}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Matrix Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1, 2], [3, 4]])\n",
    "b = torch.tensor([[5, 6], [7, 8]])\n",
    "\n",
    "print(f\"Matrix a:\\n{a}\")\n",
    "print(f\"Matrix b:\\n{b}\")\n",
    "\n",
    "# Matrix multiplication\n",
    "print(f\"\\nMatrix multiplication (torch.matmul(a, b)):\\n{torch.matmul(a, b)}\")\n",
    "print(f\"Matrix multiplication (a @ b):\\n{a @ b}\")\n",
    "\n",
    "# Element-wise multiplication\n",
    "print(f\"\\nElement-wise multiplication (a * b):\\n{a * b}\")\n",
    "\n",
    "# Transpose\n",
    "print(f\"\\nTranspose of a:\\n{a.t()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determinant\n",
    "print(f\"Determinant of a: {torch.det(a.float())}\")\n",
    "\n",
    "# Inverse\n",
    "print(f\"Inverse of a:\\n{torch.inverse(a.float())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Reduction Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(f\"Tensor x:\\n{x}\")\n",
    "\n",
    "# Sum\n",
    "print(f\"\\nSum of all elements: {torch.sum(x)}\")\n",
    "print(f\"Sum along rows (dim=0): {x.sum(dim=0)}\")\n",
    "print(f\"Sum along columns (dim=1): {x.sum(dim=1)}\")\n",
    "\n",
    "# Mean\n",
    "print(f\"\\nMean of all elements: {torch.mean(x.float())}\")\n",
    "print(f\"Mean along rows (dim=0): {x.float().mean(dim=0)}\")\n",
    "print(f\"Mean along columns (dim=1): {x.float().mean(dim=1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max and Min\n",
    "print(f\"Max of all elements: {torch.max(x)}\")\n",
    "max_values, max_indices = x.max(dim=0)\n",
    "print(f\"Max along rows (dim=0): values={max_values}, indices={max_indices}\")\n",
    "print(f\"Min of all elements: {torch.min(x)}\")\n",
    "\n",
    "# Product\n",
    "print(f\"Product of all elements: {torch.prod(x)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Reshaping Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(f\"Original tensor x:\\n{x}\")\n",
    "\n",
    "# Reshape\n",
    "print(f\"\\nReshape to (3, 2):\\n{x.reshape(3, 2)}\")\n",
    "\n",
    "# View (shares the same data with the original tensor)\n",
    "print(f\"\\nView as (6, 1):\\n{x.view(6, 1)}\")\n",
    "\n",
    "# Flatten\n",
    "print(f\"\\nFlatten: {x.flatten()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permute dimensions\n",
    "y = torch.tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])  # Shape: (2, 2, 2)\n",
    "print(f\"Original tensor y with shape {y.shape}:\\n{y}\")\n",
    "print(f\"\\nPermute dimensions (2, 0, 1) with shape {y.permute(2, 0, 1).shape}:\\n{y.permute(2, 0, 1)}\")\n",
    "\n",
    "# Squeeze and Unsqueeze\n",
    "z = torch.tensor([[[1], [2]]])  # Shape: (1, 2, 1)\n",
    "print(f\"\\nOriginal tensor z with shape {z.shape}:\\n{z}\")\n",
    "print(f\"Squeeze z with shape {z.squeeze().shape}: {z.squeeze()}\")\n",
    "print(f\"Squeeze dimension 0 with shape {z.squeeze(0).shape}:\\n{z.squeeze(0)}\")\n",
    "print(f\"Unsqueeze x at dimension 0 with shape {torch.unsqueeze(x, 0).shape}:\\n{torch.unsqueeze(x, 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. NumPy Integration\n",
    "\n",
    "PyTorch provides seamless integration with NumPy, allowing you to convert between PyTorch tensors and NumPy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert NumPy array to PyTorch tensor\n",
    "np_array = np.array([1, 2, 3])\n",
    "tensor = torch.from_numpy(np_array)\n",
    "print(f\"NumPy array: {np_array}\")\n",
    "print(f\"PyTorch tensor from NumPy: {tensor}\")\n",
    "\n",
    "# Convert PyTorch tensor to NumPy array\n",
    "tensor = torch.tensor([4, 5, 6])\n",
    "np_array = tensor.numpy()\n",
    "print(f\"\\nPyTorch tensor: {tensor}\")\n",
    "print(f\"NumPy array from tensor: {np_array}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shared memory demonstration\n",
    "np_array = np.array([1, 2, 3])\n",
    "tensor = torch.from_numpy(np_array)\n",
    "print(f\"Original NumPy array: {np_array}\")\n",
    "print(f\"Original tensor: {tensor}\")\n",
    "\n",
    "np_array[0] = 5\n",
    "print(f\"\\nModified NumPy array: {np_array}\")\n",
    "print(f\"Tensor after NumPy modification: {tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. GPU Acceleration\n",
    "\n",
    "One of the key features of PyTorch is its ability to leverage GPU acceleration for faster computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if CUDA (NVIDIA GPU) is available\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(f\"CUDA available: {cuda_available}\")\n",
    "\n",
    "# Create tensors on CPU or GPU\n",
    "if cuda_available:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using CUDA device\")\n",
    "    \n",
    "    # Create tensor directly on GPU\n",
    "    x_gpu = torch.tensor([1, 2, 3], device=device)\n",
    "    print(f\"Tensor created on GPU: {x_gpu}\")\n",
    "    \n",
    "    # Move tensor from CPU to GPU\n",
    "    x_cpu = torch.tensor([4, 5, 6])\n",
    "    x_gpu = x_cpu.to(device)\n",
    "    print(f\"Tensor moved from CPU to GPU: {x_gpu}\")\n",
    "    \n",
    "    # Move tensor back to CPU\n",
    "    x_cpu_again = x_gpu.cpu()\n",
    "    print(f\"Tensor moved back to CPU: {x_cpu_again}\")\n",
    "else:\n",
    "    print(\"CUDA not available. Using CPU only.\")\n",
    "    device = torch.device(\"cpu\")\n",
    "    x = torch.tensor([1, 2, 3])\n",
    "    print(f\"Tensor on CPU: {x}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Computational Graphs\n",
    "\n",
    "PyTorch uses a dynamic computational graph, which means the graph is built on-the-fly as operations are executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tensors with requires_grad=True to track operations\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "y = torch.tensor(3.0, requires_grad=True)\n",
    "\n",
    "print(f\"x = {x}\")\n",
    "print(f\"y = {y}\")\n",
    "\n",
    "# Build a computational graph\n",
    "z = x**2 + y**3\n",
    "print(f\"z = x^2 + y^3 = {z}\")\n",
    "\n",
    "# Compute gradients\n",
    "z.backward()\n",
    "\n",
    "# Access gradients\n",
    "print(f\"Gradient of z with respect to x (dz/dx): {x.grad}\")\n",
    "print(f\"Gradient of z with respect to y (dz/dy): {y.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient accumulation\n",
    "print(\"Gradient accumulation:\")\n",
    "\n",
    "# Reset gradients\n",
    "x.grad.zero_()\n",
    "y.grad.zero_()\n",
    "print(f\"After zeroing gradients:\")\n",
    "print(f\"x.grad = {x.grad}\")\n",
    "print(f\"y.grad = {y.grad}\")\n",
    "\n",
    "# Compute gradients multiple times\n",
    "z = x**2 + y**3\n",
    "z.backward()\n",
    "print(f\"\\nAfter first backward pass:\")\n",
    "print(f\"x.grad = {x.grad}\")\n",
    "\n",
    "z = x**2 + y**3\n",
    "z.backward()\n",
    "print(f\"\\nAfter second backward pass (gradients are accumulated):\")\n",
    "print(f\"x.grad = {x.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detach a tensor from the graph\n",
    "a = x.detach()\n",
    "print(f\"Detached tensor a = {a}\")\n",
    "print(f\"a.requires_grad = {a.requires_grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualization Example\n",
    "\n",
    "Let's visualize a simple function and its gradient using PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a range of x values\n",
    "x_range = torch.linspace(-3, 3, 100, requires_grad=True)\n",
    "\n",
    "# Define a function: f(x) = x^2\n",
    "y = x_range**2\n",
    "\n",
    "# Compute gradients for each x value\n",
    "gradients = []\n",
    "for i in range(len(x_range)):\n",
    "    if x_range.grad is not None:\n",
    "        x_range.grad.zero_()\n",
    "    y_i = x_range[i]**2\n",
    "    y_i.backward(retain_graph=True)\n",
    "    gradients.append(x_range.grad[i].item())\n",
    "\n",
    "# Convert to NumPy for plotting\n",
    "x_np = x_range.detach().numpy()\n",
    "y_np = y.detach().numpy()\n",
    "gradients_np = np.array(gradients)\n",
    "\n",
    "# Plot the function and its gradient\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x_np, y_np, 'b-', label='f(x) = x^2')\n",
    "plt.plot(x_np, gradients_np, 'r-', label=\"f'(x) = 2x\")\n",
    "plt.grid(True)\n",
    "plt.axhline(y=0, color='k', linestyle='-', alpha=0.3)\n",
    "plt.axvline(x=0, color='k', linestyle='-', alpha=0.3)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Function and its Gradient')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook covered the basics of PyTorch, including tensors, operations, NumPy integration, GPU acceleration, and computational graphs. These concepts form the foundation for building and training neural networks with PyTorch.\n",
    "\n",
    "In the next tutorial, we'll explore automatic differentiation and optimization in more detail."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
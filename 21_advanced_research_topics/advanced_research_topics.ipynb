{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 21: Advanced Research Topics\n",
    "\n",
    "This tutorial explores cutting-edge research topics in deep learning, including neural ODEs, implicit neural representations, self-supervised learning, and other emerging techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple, List, Optional, Dict\n",
    "import time\n",
    "from torchdiffeq import odeint_adjoint as odeint  # For neural ODEs\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Neural Ordinary Differential Equations (Neural ODEs)\n",
    "\n",
    "Neural ODEs represent neural networks as continuous dynamical systems, allowing for memory-efficient training and continuous-time modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ODEFunc(nn.Module):\n",
    "    \"\"\"ODE function for Neural ODE\"\"\"\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, t, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class NeuralODE(nn.Module):\n",
    "    \"\"\"Neural ODE block\"\"\"\n",
    "    def __init__(self, func, t0=0.0, t1=1.0):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "        self.t = torch.tensor([t0, t1]).float()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Solve ODE\n",
    "        self.func.nfe = 0  # Number of function evaluations\n",
    "        out = odeint(self.func, x, self.t, method='dopri5')\n",
    "        return out[1]  # Return final state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create spiral dataset for classification\n",
    "def create_spiral_data(n_samples=1000, noise=0.1):\n",
    "    \"\"\"Create spiral dataset for classification\"\"\"\n",
    "    t = torch.linspace(0, 4 * np.pi, n_samples // 2)\n",
    "    \n",
    "    # Class 0: clockwise spiral\n",
    "    x0 = t * torch.cos(t) + noise * torch.randn(n_samples // 2)\n",
    "    y0 = t * torch.sin(t) + noise * torch.randn(n_samples // 2)\n",
    "    \n",
    "    # Class 1: counter-clockwise spiral\n",
    "    x1 = -t * torch.cos(t) + noise * torch.randn(n_samples // 2)\n",
    "    y1 = t * torch.sin(t) + noise * torch.randn(n_samples // 2)\n",
    "    \n",
    "    X = torch.stack([\n",
    "        torch.cat([x0, x1]),\n",
    "        torch.cat([y0, y1])\n",
    "    ], dim=1)\n",
    "    \n",
    "    y = torch.cat([\n",
    "        torch.zeros(n_samples // 2),\n",
    "        torch.ones(n_samples // 2)\n",
    "    ]).long()\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Generate data\n",
    "X_spiral, y_spiral = create_spiral_data(n_samples=500)\n",
    "\n",
    "# Visualize data\n",
    "plt.figure(figsize=(8, 6))\n",
    "colors = ['blue', 'red']\n",
    "for i in range(2):\n",
    "    mask = y_spiral == i\n",
    "    plt.scatter(X_spiral[mask, 0], X_spiral[mask, 1], \n",
    "                c=colors[i], alpha=0.6, label=f'Class {i}')\n",
    "plt.title('Spiral Dataset')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and train Neural ODE classifier\n",
    "class ODEClassifier(nn.Module):\n",
    "    \"\"\"Classifier using Neural ODE\"\"\"\n",
    "    def __init__(self, input_dim=2, hidden_dim=64, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Linear(input_dim, hidden_dim)\n",
    "        self.ode = NeuralODE(ODEFunc(hidden_dim))\n",
    "        self.decoder = nn.Linear(hidden_dim, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.ode(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# Train Neural ODE\n",
    "print(\"Training Neural ODE classifier...\")\n",
    "ode_model = ODEClassifier().to(device)\n",
    "optimizer = optim.Adam(ode_model.parameters(), lr=0.01)\n",
    "\n",
    "X_train = X_spiral.to(device)\n",
    "y_train = y_spiral.to(device)\n",
    "\n",
    "losses = []\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    logits = ode_model(X_train)\n",
    "    loss = F.cross_entropy(logits, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    if epoch % 20 == 0:\n",
    "        acc = (logits.argmax(1) == y_train).float().mean()\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}, Accuracy: {acc:.4f}\")\n",
    "\n",
    "# Plot training curve\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(losses)\n",
    "plt.title('Neural ODE Training')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implicit Neural Representations (SIREN)\n",
    "\n",
    "SIREN (Sinusoidal Representation Networks) uses periodic activation functions to learn continuous representations of signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SineLayer(nn.Module):\n",
    "    \"\"\"Sine activation layer for SIREN\"\"\"\n",
    "    def __init__(self, in_features, out_features, bias=True, is_first=False, omega_0=30):\n",
    "        super().__init__()\n",
    "        self.omega_0 = omega_0\n",
    "        self.is_first = is_first\n",
    "        self.in_features = in_features\n",
    "        self.linear = nn.Linear(in_features, out_features, bias=bias)\n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            if self.is_first:\n",
    "                self.linear.weight.uniform_(-1 / self.in_features, 1 / self.in_features)\n",
    "            else:\n",
    "                self.linear.weight.uniform_(\n",
    "                    -np.sqrt(6 / self.in_features) / self.omega_0,\n",
    "                    np.sqrt(6 / self.in_features) / self.omega_0\n",
    "                )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return torch.sin(self.omega_0 * self.linear(x))\n",
    "\n",
    "class SIREN(nn.Module):\n",
    "    \"\"\"SIREN: Sinusoidal Representation Networks\"\"\"\n",
    "    def __init__(self, in_features, hidden_features, hidden_layers, out_features, \n",
    "                 outermost_linear=True, first_omega_0=30, hidden_omega_0=1.):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.net = []\n",
    "        self.net.append(SineLayer(in_features, hidden_features, \n",
    "                                 is_first=True, omega_0=first_omega_0))\n",
    "        \n",
    "        for i in range(hidden_layers):\n",
    "            self.net.append(SineLayer(hidden_features, hidden_features, \n",
    "                                     is_first=False, omega_0=hidden_omega_0))\n",
    "        \n",
    "        if outermost_linear:\n",
    "            final_linear = nn.Linear(hidden_features, out_features)\n",
    "            with torch.no_grad():\n",
    "                final_linear.weight.uniform_(\n",
    "                    -np.sqrt(6 / hidden_features) / hidden_omega_0,\n",
    "                    np.sqrt(6 / hidden_features) / hidden_omega_0\n",
    "                )\n",
    "            self.net.append(final_linear)\n",
    "        else:\n",
    "            self.net.append(SineLayer(hidden_features, out_features, \n",
    "                                     is_first=False, omega_0=hidden_omega_0))\n",
    "        \n",
    "        self.net = nn.Sequential(*self.net)\n",
    "    \n",
    "    def forward(self, coords):\n",
    "        return self.net(coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create image fitting task\n",
    "def create_image_coords(height, width):\n",
    "    \"\"\"Create coordinate grid for image\"\"\"\n",
    "    coords = torch.stack(torch.meshgrid(\n",
    "        torch.linspace(-1, 1, height),\n",
    "        torch.linspace(-1, 1, width),\n",
    "        indexing='ij'\n",
    "    ), dim=-1)\n",
    "    return coords.reshape(-1, 2)\n",
    "\n",
    "# Generate synthetic image\n",
    "height, width = 64, 64\n",
    "coords = create_image_coords(height, width)\n",
    "\n",
    "# Create target image (checkerboard pattern)\n",
    "target_image = ((coords[:, 0] * 5).sin() > 0) ^ ((coords[:, 1] * 5).sin() > 0)\n",
    "target_image = target_image.float().reshape(height, width)\n",
    "\n",
    "# Display target image\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(target_image, cmap='gray')\n",
    "plt.title('Target Image')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train SIREN to fit image\n",
    "print(\"Training SIREN to fit image...\")\n",
    "siren = SIREN(in_features=2, hidden_features=256, hidden_layers=3, \n",
    "              out_features=1).to(device)\n",
    "optimizer = optim.Adam(siren.parameters(), lr=1e-4)\n",
    "\n",
    "coords_train = coords.to(device)\n",
    "target_train = target_image.reshape(-1, 1).to(device)\n",
    "\n",
    "# Training loop with visualization\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "training_steps = [0, 200, 500, 1000]\n",
    "step_idx = 0\n",
    "\n",
    "for step in range(1001):\n",
    "    optimizer.zero_grad()\n",
    "    pred = siren(coords_train)\n",
    "    loss = F.mse_loss(pred, target_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if step in training_steps:\n",
    "        with torch.no_grad():\n",
    "            pred_image = siren(coords_train).cpu().reshape(height, width)\n",
    "            axes[step_idx].imshow(pred_image, cmap='gray')\n",
    "            axes[step_idx].set_title(f'Step {step}')\n",
    "            axes[step_idx].axis('off')\n",
    "            step_idx += 1\n",
    "        print(f\"Step {step}, Loss: {loss.item():.6f}\")\n",
    "\n",
    "plt.suptitle('SIREN Image Fitting Progress')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Self-Supervised Learning (SimCLR)\n",
    "\n",
    "SimCLR is a contrastive learning framework that learns representations without labels by maximizing agreement between differently augmented views of the same data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimCLR(nn.Module):\n",
    "    \"\"\"Simplified SimCLR for self-supervised learning\"\"\"\n",
    "    def __init__(self, encoder_dim=128, projection_dim=64):\n",
    "        super().__init__()\n",
    "        # Simple encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(784, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, encoder_dim)\n",
    "        )\n",
    "        \n",
    "        # Projection head\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(encoder_dim, projection_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(projection_dim, projection_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        z = self.projection(h)\n",
    "        return h, z\n",
    "\n",
    "def nt_xent_loss(z1, z2, temperature=0.5):\n",
    "    \"\"\"NT-Xent loss for contrastive learning\"\"\"\n",
    "    batch_size = z1.shape[0]\n",
    "    \n",
    "    # Normalize embeddings\n",
    "    z1 = F.normalize(z1, dim=1)\n",
    "    z2 = F.normalize(z2, dim=1)\n",
    "    \n",
    "    # Compute similarity matrix\n",
    "    representations = torch.cat([z1, z2], dim=0)\n",
    "    similarity_matrix = F.cosine_similarity(\n",
    "        representations.unsqueeze(1), \n",
    "        representations.unsqueeze(0), \n",
    "        dim=2\n",
    "    )\n",
    "    \n",
    "    # Create positive mask\n",
    "    labels = torch.cat([torch.arange(batch_size), torch.arange(batch_size)], dim=0)\n",
    "    labels = (labels.unsqueeze(0) == labels.unsqueeze(1)).float()\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    # Mask out self-similarity\n",
    "    mask = torch.eye(labels.shape[0], dtype=torch.bool).to(device)\n",
    "    labels = labels[~mask].view(labels.shape[0], -1)\n",
    "    similarity_matrix = similarity_matrix[~mask].view(similarity_matrix.shape[0], -1)\n",
    "    \n",
    "    # Select positives\n",
    "    positives = similarity_matrix[labels.bool()].view(labels.shape[0], -1)\n",
    "    \n",
    "    # Select negatives\n",
    "    negatives = similarity_matrix[~labels.bool()].view(similarity_matrix.shape[0], -1)\n",
    "    \n",
    "    # Compute loss\n",
    "    logits = torch.cat([positives, negatives], dim=1)\n",
    "    labels = torch.zeros(logits.shape[0], dtype=torch.long).to(device)\n",
    "    \n",
    "    logits = logits / temperature\n",
    "    return F.cross_entropy(logits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation for self-supervised learning\n",
    "def augment_data(x, noise_factor=0.1):\n",
    "    \"\"\"Simple augmentation by adding noise\"\"\"\n",
    "    aug1 = x + torch.randn_like(x) * noise_factor\n",
    "    aug2 = x + torch.randn_like(x) * noise_factor\n",
    "    return aug1, aug2\n",
    "\n",
    "# Train SimCLR\n",
    "print(\"Training SimCLR...\")\n",
    "simclr_model = SimCLR().to(device)\n",
    "optimizer = optim.Adam(simclr_model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "batch_size = 128\n",
    "losses = []\n",
    "\n",
    "for epoch in range(50):\n",
    "    # Random data (in practice, use real images)\n",
    "    x = torch.randn(batch_size, 784).to(device)\n",
    "    \n",
    "    # Create augmented views\n",
    "    x1, x2 = augment_data(x)\n",
    "    \n",
    "    # Forward pass\n",
    "    _, z1 = simclr_model(x1)\n",
    "    _, z2 = simclr_model(x2)\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = nt_xent_loss(z1, z2)\n",
    "    \n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Plot training curve\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(losses)\n",
    "plt.title('SimCLR Training')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('NT-Xent Loss')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Diffusion Models (Simplified)\n",
    "\n",
    "Diffusion models generate data by gradually denoising random noise through a learned reverse diffusion process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDiffusion(nn.Module):\n",
    "    \"\"\"Simplified diffusion model for 1D data\"\"\"\n",
    "    def __init__(self, dim=2, time_dim=16):\n",
    "        super().__init__()\n",
    "        self.time_dim = time_dim\n",
    "        \n",
    "        # Time embedding\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            nn.Linear(1, time_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(time_dim, time_dim)\n",
    "        )\n",
    "        \n",
    "        # Denoising network\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim + time_dim, 128),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(128, dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        # Embed time\n",
    "        t_emb = self.time_mlp(t.unsqueeze(-1))\n",
    "        # Concatenate with input\n",
    "        h = torch.cat([x, t_emb], dim=-1)\n",
    "        # Predict noise\n",
    "        return self.net(h)\n",
    "\n",
    "# Diffusion process utilities\n",
    "def q_sample(x_0, t, noise=None, beta_schedule='linear', n_timesteps=100):\n",
    "    \"\"\"Forward diffusion process\"\"\"\n",
    "    if noise is None:\n",
    "        noise = torch.randn_like(x_0)\n",
    "    \n",
    "    # Simple linear schedule\n",
    "    betas = torch.linspace(0.0001, 0.02, n_timesteps)\n",
    "    alphas = 1.0 - betas\n",
    "    alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
    "    \n",
    "    # Get alpha values for timestep t\n",
    "    sqrt_alphas_cumprod = alphas_cumprod.sqrt()\n",
    "    sqrt_one_minus_alphas_cumprod = (1.0 - alphas_cumprod).sqrt()\n",
    "    \n",
    "    # Extract values for batch\n",
    "    sqrt_alphas_cumprod_t = sqrt_alphas_cumprod[t].reshape(-1, 1)\n",
    "    sqrt_one_minus_alphas_cumprod_t = sqrt_one_minus_alphas_cumprod[t].reshape(-1, 1)\n",
    "    \n",
    "    # Add noise\n",
    "    return sqrt_alphas_cumprod_t * x_0 + sqrt_one_minus_alphas_cumprod_t * noise, noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 2D data (two moons)\n",
    "from sklearn.datasets import make_moons\n",
    "X_moons, _ = make_moons(n_samples=1000, noise=0.1)\n",
    "X_moons = torch.FloatTensor(X_moons)\n",
    "\n",
    "# Visualize data and diffusion process\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "# Original data\n",
    "axes[0].scatter(X_moons[:, 0], X_moons[:, 1], alpha=0.5)\n",
    "axes[0].set_title('Original Data')\n",
    "axes[0].set_xlabel('X')\n",
    "axes[0].set_ylabel('Y')\n",
    "\n",
    "# Show diffusion process at different timesteps\n",
    "timesteps = [10, 50, 99]\n",
    "for i, t in enumerate(timesteps):\n",
    "    x_noisy, _ = q_sample(X_moons[:100], torch.tensor([t]*100), n_timesteps=100)\n",
    "    axes[i+1].scatter(x_noisy[:, 0], x_noisy[:, 1], alpha=0.5)\n",
    "    axes[i+1].set_title(f'Timestep {t}')\n",
    "    axes[i+1].set_xlabel('X')\n",
    "    axes[i+1].set_ylabel('Y')\n",
    "\n",
    "plt.suptitle('Forward Diffusion Process')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train diffusion model\n",
    "print(\"Training simplified diffusion model...\")\n",
    "diffusion_model = SimpleDiffusion(dim=2).to(device)\n",
    "optimizer = optim.Adam(diffusion_model.parameters(), lr=0.001)\n",
    "\n",
    "n_timesteps = 100\n",
    "batch_size = 64\n",
    "losses = []\n",
    "\n",
    "for epoch in range(200):\n",
    "    # Sample batch\n",
    "    idx = torch.randint(0, len(X_moons), (batch_size,))\n",
    "    x_0 = X_moons[idx].to(device)\n",
    "    \n",
    "    # Sample timesteps\n",
    "    t = torch.randint(0, n_timesteps, (batch_size,)).to(device)\n",
    "    \n",
    "    # Add noise\n",
    "    x_t, noise = q_sample(x_0, t, n_timesteps=n_timesteps)\n",
    "    \n",
    "    # Predict noise\n",
    "    predicted_noise = diffusion_model(x_t, t.float() / n_timesteps)\n",
    "    \n",
    "    # MSE loss\n",
    "    loss = F.mse_loss(predicted_noise, noise)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    if epoch % 40 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Plot training curve\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(losses)\n",
    "plt.title('Diffusion Model Training')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Advanced Transformer Techniques\n",
    "\n",
    "Exploring recent innovations in transformer architectures including RoPE, Flash Attention, and Mixture of Experts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RotaryPositionalEmbedding(nn.Module):\n",
    "    \"\"\"Rotary Positional Embedding (RoPE)\"\"\"\n",
    "    def __init__(self, dim, max_seq_len=1024):\n",
    "        super().__init__()\n",
    "        inv_freq = 1.0 / (10000 ** (torch.arange(0, dim, 2).float() / dim))\n",
    "        t = torch.arange(max_seq_len).float()\n",
    "        freqs = torch.outer(t, inv_freq)\n",
    "        self.register_buffer('cos', freqs.cos())\n",
    "        self.register_buffer('sin', freqs.sin())\n",
    "    \n",
    "    def forward(self, x, seq_len=None):\n",
    "        if seq_len is None:\n",
    "            seq_len = x.shape[1]\n",
    "        \n",
    "        cos = self.cos[:seq_len, :]\n",
    "        sin = self.sin[:seq_len, :]\n",
    "        \n",
    "        # Apply rotation\n",
    "        x1, x2 = x.chunk(2, dim=-1)\n",
    "        x_rot = torch.cat([-x2, x1], dim=-1)\n",
    "        \n",
    "        x_pos = x * cos + x_rot * sin\n",
    "        return x_pos\n",
    "\n",
    "class MoELayer(nn.Module):\n",
    "    \"\"\"Mixture of Experts layer\"\"\"\n",
    "    def __init__(self, dim, num_experts=4, expert_capacity=2):\n",
    "        super().__init__()\n",
    "        self.num_experts = num_experts\n",
    "        self.expert_capacity = expert_capacity\n",
    "        \n",
    "        # Gate network\n",
    "        self.gate = nn.Linear(dim, num_experts)\n",
    "        \n",
    "        # Experts\n",
    "        self.experts = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(dim, 4 * dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(4 * dim, dim)\n",
    "            ) for _ in range(num_experts)\n",
    "        ])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, dim = x.shape\n",
    "        \n",
    "        # Compute gates\n",
    "        gates = F.softmax(self.gate(x), dim=-1)\n",
    "        \n",
    "        # Top-k routing\n",
    "        topk_gates, topk_indices = gates.topk(2, dim=-1)\n",
    "        topk_gates = topk_gates / topk_gates.sum(dim=-1, keepdim=True)\n",
    "        \n",
    "        # Process through experts (simplified)\n",
    "        output = torch.zeros_like(x)\n",
    "        for i in range(self.num_experts):\n",
    "            expert_mask = (topk_indices == i).any(dim=-1)\n",
    "            if expert_mask.any():\n",
    "                expert_input = x[expert_mask]\n",
    "                expert_output = self.experts[i](expert_input)\n",
    "                \n",
    "                # Weighted combination\n",
    "                expert_gates = topk_gates[expert_mask]\n",
    "                expert_gates = expert_gates[topk_indices[expert_mask] == i].unsqueeze(-1)\n",
    "                \n",
    "                output[expert_mask] += expert_gates * expert_output\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate advanced transformer components\n",
    "print(\"Testing advanced transformer components...\")\n",
    "\n",
    "# RoPE\n",
    "rope = RotaryPositionalEmbedding(dim=64)\n",
    "x = torch.randn(2, 10, 64)  # [batch, seq_len, dim]\n",
    "x_pos = rope(x)\n",
    "print(f\"RoPE output shape: {x_pos.shape}\")\n",
    "\n",
    "# MoE\n",
    "moe = MoELayer(dim=64, num_experts=4)\n",
    "moe_out = moe(x)\n",
    "print(f\"MoE output shape: {moe_out.shape}\")\n",
    "\n",
    "# Visualize expert routing\n",
    "with torch.no_grad():\n",
    "    gates = F.softmax(moe.gate(x[0]), dim=-1)  # First sample\n",
    "    \n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(gates.numpy().T, aspect='auto', cmap='hot')\n",
    "plt.colorbar(label='Gate Probability')\n",
    "plt.xlabel('Sequence Position')\n",
    "plt.ylabel('Expert ID')\n",
    "plt.title('Expert Routing Visualization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Emerging Techniques: HyperNetworks and Adaptive Architectures\n",
    "\n",
    "Exploring networks that generate other networks and architectures that adapt based on input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperNetwork(nn.Module):\n",
    "    \"\"\"Network that generates weights for another network\"\"\"\n",
    "    def __init__(self, z_dim=10, main_input_dim=2, main_hidden_dim=32, main_output_dim=1):\n",
    "        super().__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.main_dims = [main_input_dim, main_hidden_dim, main_output_dim]\n",
    "        \n",
    "        # Calculate total parameters needed\n",
    "        total_params = 0\n",
    "        for i in range(len(self.main_dims) - 1):\n",
    "            total_params += self.main_dims[i] * self.main_dims[i+1]\n",
    "            total_params += self.main_dims[i+1]  # biases\n",
    "        \n",
    "        # Hypernetwork that generates main network weights\n",
    "        self.hypernet = nn.Sequential(\n",
    "            nn.Linear(z_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, total_params)\n",
    "        )\n",
    "        \n",
    "    def forward(self, z, x):\n",
    "        # Generate weights\n",
    "        params = self.hypernet(z)\n",
    "        \n",
    "        # Extract weights and biases\n",
    "        idx = 0\n",
    "        for i in range(len(self.main_dims) - 1):\n",
    "            w_size = self.main_dims[i] * self.main_dims[i+1]\n",
    "            b_size = self.main_dims[i+1]\n",
    "            \n",
    "            w = params[idx:idx+w_size].view(self.main_dims[i+1], self.main_dims[i])\n",
    "            b = params[idx+w_size:idx+w_size+b_size]\n",
    "            idx += w_size + b_size\n",
    "            \n",
    "            # Apply layer\n",
    "            x = F.linear(x, w, b)\n",
    "            if i < len(self.main_dims) - 2:\n",
    "                x = F.relu(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Test hypernetwork\n",
    "hypernet = HyperNetwork()\n",
    "z = torch.randn(1, 10)  # Conditioning vector\n",
    "x = torch.randn(5, 2)   # Input data\n",
    "output = hypernet(z, x)\n",
    "print(f\"HyperNetwork output shape: {output.shape}\")\n",
    "\n",
    "# Visualize how different z values produce different functions\n",
    "x_test = torch.linspace(-2, 2, 100).unsqueeze(1)\n",
    "x_test = torch.cat([x_test, torch.zeros_like(x_test)], dim=1)  # 2D input\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(5):\n",
    "    z = torch.randn(1, 10)\n",
    "    y = hypernet(z, x_test)\n",
    "    plt.plot(x_test[:, 0], y.detach().numpy(), label=f'Function {i+1}')\n",
    "\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Different Functions Generated by HyperNetwork')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Research Directions\n",
    "\n",
    "This tutorial covered several cutting-edge research topics in deep learning. Let's summarize the key concepts and future directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comprehensive visualization of all techniques\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# Neural ODE trajectories\n",
    "ax = axes[0, 0]\n",
    "with torch.no_grad():\n",
    "    # Sample points\n",
    "    x_test = torch.randn(100, 2) * 2\n",
    "    x_encoded = ode_model.encoder(x_test)\n",
    "    \n",
    "    # Get intermediate states\n",
    "    t = torch.linspace(0, 1, 20)\n",
    "    trajectory = odeint(ode_model.ode.func, x_encoded, t, method='dopri5')\n",
    "    \n",
    "    # Plot some trajectories\n",
    "    for i in range(5):\n",
    "        traj = trajectory[:, i, :2].numpy()  # First 2 dimensions\n",
    "        ax.plot(traj[:, 0], traj[:, 1], alpha=0.7)\n",
    "    \n",
    "ax.set_title('Neural ODE Trajectories')\n",
    "ax.set_xlabel('Dimension 1')\n",
    "ax.set_ylabel('Dimension 2')\n",
    "\n",
    "# SIREN frequency analysis\n",
    "ax = axes[0, 1]\n",
    "with torch.no_grad():\n",
    "    # Get SIREN activations\n",
    "    activations = []\n",
    "    def hook(module, input, output):\n",
    "        activations.append(output.detach().cpu())\n",
    "    \n",
    "    handle = siren.net[0].register_forward_hook(hook)\n",
    "    _ = siren(coords[:100])\n",
    "    handle.remove()\n",
    "    \n",
    "    # Plot activation histogram\n",
    "    ax.hist(activations[0].numpy().flatten(), bins=50, alpha=0.7)\n",
    "    ax.set_title('SIREN Activation Distribution')\n",
    "    ax.set_xlabel('Activation Value')\n",
    "    ax.set_ylabel('Frequency')\n",
    "\n",
    "# Self-supervised representations\n",
    "ax = axes[0, 2]\n",
    "with torch.no_grad():\n",
    "    # Generate random data\n",
    "    x_test = torch.randn(200, 784).to(device)\n",
    "    representations, _ = simclr_model(x_test)\n",
    "    representations = representations.cpu().numpy()\n",
    "    \n",
    "    # Simple 2D projection for visualization\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    rep_2d = pca.fit_transform(representations)\n",
    "    \n",
    "    ax.scatter(rep_2d[:, 0], rep_2d[:, 1], alpha=0.6)\n",
    "    ax.set_title('Self-Supervised Representations')\n",
    "    ax.set_xlabel('PC 1')\n",
    "    ax.set_ylabel('PC 2')\n",
    "\n",
    "# Diffusion process\n",
    "ax = axes[1, 0]\n",
    "# Show original data\n",
    "ax.scatter(X_moons[:, 0], X_moons[:, 1], alpha=0.3, label='Original', s=20)\n",
    "\n",
    "# Show noisy data at different timesteps\n",
    "for t in [25, 50, 75]:\n",
    "    x_noisy, _ = q_sample(X_moons[:100], torch.tensor([t]*100), n_timesteps=100)\n",
    "    ax.scatter(x_noisy[:, 0], x_noisy[:, 1], alpha=0.3, \n",
    "               label=f't={t}', s=10)\n",
    "\n",
    "ax.set_title('Diffusion Process')\n",
    "ax.legend()\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "\n",
    "# Research timeline\n",
    "ax = axes[1, 1]\n",
    "years = [2018, 2019, 2020, 2021, 2022, 2023]\n",
    "topics = ['BERT', 'GPT-2', 'ViT', 'DALL-E', 'ChatGPT', 'GPT-4']\n",
    "impact = [85, 88, 82, 90, 95, 98]\n",
    "\n",
    "ax.plot(years, impact, 'o-', markersize=10, linewidth=2)\n",
    "for i, txt in enumerate(topics):\n",
    "    ax.annotate(txt, (years[i], impact[i]), \n",
    "                xytext=(5, 5), textcoords='offset points')\n",
    "\n",
    "ax.set_title('Recent AI Breakthroughs')\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Impact Score')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Research areas comparison\n",
    "ax = axes[1, 2]\n",
    "areas = ['Neural\\nODEs', 'Implicit\\nNeural\\nReps', 'Self-\\nSupervised', \n",
    "         'Diffusion\\nModels', 'Advanced\\nTransformers']\n",
    "complexity = [7, 6, 5, 8, 9]\n",
    "impact = [6, 7, 9, 10, 10]\n",
    "\n",
    "ax.scatter(complexity, impact, s=200, alpha=0.6)\n",
    "for i, txt in enumerate(areas):\n",
    "    ax.annotate(txt, (complexity[i], impact[i]), \n",
    "                ha='center', va='center', fontsize=8)\n",
    "\n",
    "ax.set_xlabel('Implementation Complexity')\n",
    "ax.set_ylabel('Research Impact')\n",
    "ax.set_title('Research Areas Comparison')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Advanced Research Topics Overview', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary\n",
    "print(\"Advanced Research Topics Summary\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "research_areas = {\n",
    "    \"Neural ODEs\": {\n",
    "        \"Key Idea\": \"Continuous-depth neural networks\",\n",
    "        \"Advantages\": \"Memory efficient, continuous dynamics\",\n",
    "        \"Applications\": \"Time series, physics simulation\"\n",
    "    },\n",
    "    \"Implicit Neural Representations\": {\n",
    "        \"Key Idea\": \"Coordinate-based networks\",\n",
    "        \"Advantages\": \"Continuous, resolution-agnostic\",\n",
    "        \"Applications\": \"3D reconstruction, image compression\"\n",
    "    },\n",
    "    \"Self-Supervised Learning\": {\n",
    "        \"Key Idea\": \"Learning without labels\",\n",
    "        \"Advantages\": \"Leverages unlabeled data\",\n",
    "        \"Applications\": \"Representation learning, pretraining\"\n",
    "    },\n",
    "    \"Diffusion Models\": {\n",
    "        \"Key Idea\": \"Generation via denoising\",\n",
    "        \"Advantages\": \"High quality, stable training\",\n",
    "        \"Applications\": \"Image generation, audio synthesis\"\n",
    "    },\n",
    "    \"Advanced Transformers\": {\n",
    "        \"Key Idea\": \"Efficient attention mechanisms\",\n",
    "        \"Advantages\": \"Scalability, performance\",\n",
    "        \"Applications\": \"NLP, computer vision, multimodal\"\n",
    "    }\n",
    "}\n",
    "\n",
    "for area, details in research_areas.items():\n",
    "    print(f\"\\n{area}:\")\n",
    "    for key, value in details.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\nFuture Directions:\")\n",
    "print(\"- Neuromorphic computing\")\n",
    "print(\"- Quantum machine learning\")\n",
    "print(\"- Causal representation learning\")\n",
    "print(\"- Continual learning\")\n",
    "print(\"- Energy-efficient AI\")\n",
    "print(\"- Interpretable AI\")\n",
    "\n",
    "print(\"\\nKey Takeaways:\")\n",
    "print(\"- Research is rapidly evolving\")\n",
    "print(\"- Cross-pollination between fields is common\")\n",
    "print(\"- Theory and practice go hand in hand\")\n",
    "print(\"- Open problems abound\")\n",
    "print(\"- The field needs diverse perspectives\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
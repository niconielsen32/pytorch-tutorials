{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 20: Bayesian Deep Learning\n",
    "\n",
    "This tutorial explores Bayesian approaches to deep learning, focusing on uncertainty quantification and probabilistic modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Normal, Categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple, List, Optional\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.datasets import make_moons, make_circles\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Set random seeds\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Understanding Uncertainty in Deep Learning\n",
    "\n",
    "There are two main types of uncertainty:\n",
    "- **Aleatoric uncertainty**: Irreducible noise in the data\n",
    "- **Epistemic uncertainty**: Uncertainty due to lack of knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data with different types of uncertainty\n",
    "def generate_data_with_uncertainty(n_samples=200):\n",
    "    \"\"\"Generate data with epistemic and aleatoric uncertainty\"\"\"\n",
    "    x = np.linspace(-3, 3, n_samples)\n",
    "    \n",
    "    # True function\n",
    "    y_true = np.sin(x) + 0.3 * np.cos(2 * x)\n",
    "    \n",
    "    # Aleatoric uncertainty (heteroscedastic noise)\n",
    "    noise_std = 0.05 + 0.15 * np.exp(-x**2)  # Higher noise at extremes\n",
    "    y_aleatoric = y_true + np.random.normal(0, noise_std)\n",
    "    \n",
    "    # Epistemic uncertainty (remove data in certain regions)\n",
    "    mask1 = (x > -1.5) & (x < -0.5)\n",
    "    mask2 = (x > 0.5) & (x < 1.5)\n",
    "    mask = ~(mask1 | mask2)\n",
    "    x_epistemic = x[mask]\n",
    "    y_epistemic = y_aleatoric[mask]\n",
    "    \n",
    "    return x, y_true, y_aleatoric, x_epistemic, y_epistemic, noise_std\n",
    "\n",
    "x, y_true, y_aleatoric, x_epistemic, y_epistemic, noise_std = generate_data_with_uncertainty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize uncertainty types\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Aleatoric uncertainty\n",
    "axes[0].plot(x, y_true, 'k-', label='True function', linewidth=2)\n",
    "axes[0].scatter(x[::5], y_aleatoric[::5], alpha=0.6, s=30, label='Noisy observations')\n",
    "axes[0].fill_between(x, y_true - 2*noise_std, y_true + 2*noise_std, \n",
    "                     alpha=0.3, label='Aleatoric uncertainty (±2σ)')\n",
    "axes[0].set_xlabel('x', fontsize=12)\n",
    "axes[0].set_ylabel('y', fontsize=12)\n",
    "axes[0].set_title('Aleatoric Uncertainty (Data Noise)', fontsize=14)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Epistemic uncertainty\n",
    "axes[1].plot(x, y_true, 'k-', label='True function', linewidth=2)\n",
    "axes[1].scatter(x_epistemic, y_epistemic, alpha=0.6, s=30, label='Available data')\n",
    "axes[1].axvspan(-1.5, -0.5, alpha=0.2, color='red', label='High epistemic uncertainty')\n",
    "axes[1].axvspan(0.5, 1.5, alpha=0.2, color='red')\n",
    "axes[1].set_xlabel('x', fontsize=12)\n",
    "axes[1].set_ylabel('y', fontsize=12)\n",
    "axes[1].set_title('Epistemic Uncertainty (Lack of Data)', fontsize=14)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Key Insights:\")\n",
    "print(\"• Aleatoric uncertainty: Cannot be reduced with more data\")\n",
    "print(\"• Epistemic uncertainty: Can be reduced by collecting more data\")\n",
    "print(\"• Both types are important for robust decision making\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Monte Carlo Dropout\n",
    "\n",
    "MC Dropout is a simple yet effective method for uncertainty estimation using dropout at test time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCDropoutNet(nn.Module):\n",
    "    \"\"\"Neural network with Monte Carlo Dropout for uncertainty estimation\"\"\"\n",
    "    def __init__(self, input_dim=1, hidden_dim=100, output_dim=1, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        # Dropout layers\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "    def forward(self, x, training=True):\n",
    "        # Apply dropout even during evaluation for MC Dropout\n",
    "        if training:\n",
    "            self.train()\n",
    "        else:\n",
    "            self.eval()\n",
    "            # Override eval mode for dropout layers\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, nn.Dropout):\n",
    "                    m.train()\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def predict_with_uncertainty(self, x, n_samples=50):\n",
    "        \"\"\"Make predictions with uncertainty using MC Dropout\"\"\"\n",
    "        self.eval()  # Set to eval mode\n",
    "        predictions = []\n",
    "        \n",
    "        for _ in range(n_samples):\n",
    "            with torch.no_grad():\n",
    "                pred = self.forward(x, training=False)\n",
    "                predictions.append(pred)\n",
    "        \n",
    "        predictions = torch.stack(predictions)\n",
    "        mean = predictions.mean(dim=0)\n",
    "        std = predictions.std(dim=0)\n",
    "        \n",
    "        return mean, std, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train MC Dropout model\n",
    "def train_mc_dropout_model(x_train, y_train, epochs=1500, dropout_rate=0.2):\n",
    "    \"\"\"Train MC Dropout model\"\"\"\n",
    "    model = MCDropoutNet(dropout_rate=dropout_rate).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=100, factor=0.5)\n",
    "    \n",
    "    x_tensor = torch.FloatTensor(x_train).unsqueeze(1).to(device)\n",
    "    y_tensor = torch.FloatTensor(y_train).unsqueeze(1).to(device)\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(x_tensor)\n",
    "        loss = F.mse_loss(output, y_tensor)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step(loss)\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        if epoch % 300 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    return model, losses\n",
    "\n",
    "# Train model\n",
    "print(\"Training MC Dropout model...\")\n",
    "mc_model, mc_losses = train_mc_dropout_model(x_epistemic, y_epistemic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions with uncertainty\n",
    "x_test = torch.FloatTensor(x).unsqueeze(1).to(device)\n",
    "mean_pred, std_pred, all_preds = mc_model.predict_with_uncertainty(x_test, n_samples=100)\n",
    "\n",
    "# Convert to numpy\n",
    "mean_pred = mean_pred.cpu().numpy().flatten()\n",
    "std_pred = std_pred.cpu().numpy().flatten()\n",
    "all_preds = all_preds.cpu().numpy()\n",
    "\n",
    "# Visualize MC Dropout predictions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Predictions with uncertainty\n",
    "ax = axes[0]\n",
    "ax.plot(x, y_true, 'k-', label='True function', linewidth=2)\n",
    "ax.scatter(x_epistemic, y_epistemic, alpha=0.5, s=30, label='Training data')\n",
    "ax.plot(x, mean_pred, 'b-', label='MC Dropout mean', linewidth=2)\n",
    "ax.fill_between(x, mean_pred - 2*std_pred, mean_pred + 2*std_pred, \n",
    "                alpha=0.3, label='Uncertainty (±2σ)')\n",
    "\n",
    "# Highlight uncertainty regions\n",
    "ax.axvspan(-1.5, -0.5, alpha=0.1, color='red')\n",
    "ax.axvspan(0.5, 1.5, alpha=0.1, color='red')\n",
    "ax.set_xlabel('x', fontsize=12)\n",
    "ax.set_ylabel('y', fontsize=12)\n",
    "ax.set_title('MC Dropout Uncertainty Estimation', fontsize=14)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Sample predictions\n",
    "ax = axes[1]\n",
    "ax.plot(x, y_true, 'k-', label='True function', linewidth=2)\n",
    "ax.scatter(x_epistemic, y_epistemic, alpha=0.5, s=30, label='Training data')\n",
    "\n",
    "# Plot some individual predictions\n",
    "for i in range(min(20, all_preds.shape[0])):\n",
    "    ax.plot(x, all_preds[i, :, 0], 'b-', alpha=0.1, linewidth=0.5)\n",
    "\n",
    "ax.plot(x, mean_pred, 'r-', label='Mean prediction', linewidth=2)\n",
    "ax.set_xlabel('x', fontsize=12)\n",
    "ax.set_ylabel('y', fontsize=12)\n",
    "ax.set_title('MC Dropout Sample Predictions', fontsize=14)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analyze uncertainty\n",
    "data_regions = ~(((x > -1.5) & (x < -0.5)) | ((x > 0.5) & (x < 1.5)))\n",
    "no_data_regions = ((x > -1.5) & (x < -0.5)) | ((x > 0.5) & (x < 1.5))\n",
    "\n",
    "print(f\"Average uncertainty in data regions: {std_pred[data_regions].mean():.3f}\")\n",
    "print(f\"Average uncertainty in no-data regions: {std_pred[no_data_regions].mean():.3f}\")\n",
    "print(f\"Uncertainty ratio: {std_pred[no_data_regions].mean() / std_pred[data_regions].mean():.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Bayesian Neural Networks\n",
    "\n",
    "Bayesian Neural Networks place distributions over weights instead of point estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianLinear(nn.Module):\n",
    "    \"\"\"Bayesian linear layer with weight uncertainty\"\"\"\n",
    "    def __init__(self, in_features, out_features, prior_std=1.0):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        \n",
    "        # Weight parameters (mean and log variance)\n",
    "        self.weight_mu = nn.Parameter(torch.randn(out_features, in_features) * 0.1)\n",
    "        self.weight_rho = nn.Parameter(torch.randn(out_features, in_features) * -3)\n",
    "        \n",
    "        # Bias parameters\n",
    "        self.bias_mu = nn.Parameter(torch.zeros(out_features))\n",
    "        self.bias_rho = nn.Parameter(torch.randn(out_features) * -3)\n",
    "        \n",
    "        # Prior distributions\n",
    "        self.weight_prior = Normal(0, prior_std)\n",
    "        self.bias_prior = Normal(0, prior_std)\n",
    "        \n",
    "        # For KL divergence\n",
    "        self.kl_divergence = 0\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Sample weights and biases using reparameterization trick\n",
    "        weight_sigma = torch.log1p(torch.exp(self.weight_rho))\n",
    "        weight_dist = Normal(self.weight_mu, weight_sigma)\n",
    "        weight = weight_dist.rsample()\n",
    "        \n",
    "        bias_sigma = torch.log1p(torch.exp(self.bias_rho))\n",
    "        bias_dist = Normal(self.bias_mu, bias_sigma)\n",
    "        bias = bias_dist.rsample()\n",
    "        \n",
    "        # Compute KL divergence\n",
    "        self.kl_divergence = (\n",
    "            torch.distributions.kl_divergence(weight_dist, self.weight_prior).sum() +\n",
    "            torch.distributions.kl_divergence(bias_dist, self.bias_prior).sum()\n",
    "        )\n",
    "        \n",
    "        return F.linear(x, weight, bias)\n",
    "\n",
    "class BayesianNN(nn.Module):\n",
    "    \"\"\"Bayesian Neural Network\"\"\"\n",
    "    def __init__(self, input_dim=1, hidden_dim=50, output_dim=1, prior_std=1.0):\n",
    "        super().__init__()\n",
    "        self.fc1 = BayesianLinear(input_dim, hidden_dim, prior_std)\n",
    "        self.fc2 = BayesianLinear(hidden_dim, hidden_dim, prior_std)\n",
    "        self.fc3 = BayesianLinear(hidden_dim, output_dim, prior_std)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def kl_divergence(self):\n",
    "        \"\"\"Total KL divergence of the model\"\"\"\n",
    "        kl = 0\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, BayesianLinear):\n",
    "                kl += module.kl_divergence\n",
    "        return kl\n",
    "    \n",
    "    def predict_with_uncertainty(self, x, n_samples=50):\n",
    "        \"\"\"Make predictions with uncertainty\"\"\"\n",
    "        self.eval()\n",
    "        predictions = []\n",
    "        \n",
    "        for _ in range(n_samples):\n",
    "            with torch.no_grad():\n",
    "                pred = self.forward(x)\n",
    "                predictions.append(pred)\n",
    "        \n",
    "        predictions = torch.stack(predictions)\n",
    "        mean = predictions.mean(dim=0)\n",
    "        std = predictions.std(dim=0)\n",
    "        \n",
    "        return mean, std, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Bayesian Neural Network\n",
    "def train_bayesian_nn(x_train, y_train, epochs=2000, kl_weight=0.01):\n",
    "    \"\"\"Train Bayesian Neural Network with variational inference\"\"\"\n",
    "    model = BayesianNN(prior_std=1.0).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "    \n",
    "    x_tensor = torch.FloatTensor(x_train).unsqueeze(1).to(device)\n",
    "    y_tensor = torch.FloatTensor(y_train).unsqueeze(1).to(device)\n",
    "    \n",
    "    n_data = len(x_train)\n",
    "    losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(x_tensor)\n",
    "        \n",
    "        # ELBO loss = -log likelihood + KL divergence\n",
    "        nll = F.mse_loss(output, y_tensor, reduction='sum')\n",
    "        kl = model.kl_divergence()\n",
    "        loss = nll + kl_weight * kl / n_data\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        if epoch % 400 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.item():.4f}, \"\n",
    "                  f\"NLL: {nll.item():.4f}, KL: {kl.item():.4f}\")\n",
    "    \n",
    "    return model, losses\n",
    "\n",
    "# Train Bayesian NN\n",
    "print(\"Training Bayesian Neural Network...\")\n",
    "bnn_model, bnn_losses = train_bayesian_nn(x_epistemic, y_epistemic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "mean_bnn, std_bnn, all_preds_bnn = bnn_model.predict_with_uncertainty(x_test, n_samples=100)\n",
    "mean_bnn = mean_bnn.cpu().numpy().flatten()\n",
    "std_bnn = std_bnn.cpu().numpy().flatten()\n",
    "\n",
    "# Visualize weight distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Plot weight distributions for first layer\n",
    "ax = axes[0, 0]\n",
    "weight_mu = bnn_model.fc1.weight_mu.detach().cpu().numpy().flatten()\n",
    "weight_rho = bnn_model.fc1.weight_rho.detach().cpu().numpy().flatten()\n",
    "weight_sigma = np.log1p(np.exp(weight_rho))\n",
    "\n",
    "ax.hist(weight_mu, bins=30, alpha=0.5, label='Weight means', density=True)\n",
    "ax.hist(weight_sigma, bins=30, alpha=0.5, label='Weight stds', density=True)\n",
    "ax.set_xlabel('Value')\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_title('BNN First Layer Weight Distribution')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# BNN predictions\n",
    "ax = axes[0, 1]\n",
    "ax.plot(x, y_true, 'k-', label='True function', linewidth=2)\n",
    "ax.scatter(x_epistemic, y_epistemic, alpha=0.5, s=30, label='Training data')\n",
    "ax.plot(x, mean_bnn, 'g-', label='BNN mean', linewidth=2)\n",
    "ax.fill_between(x, mean_bnn - 2*std_bnn, mean_bnn + 2*std_bnn, \n",
    "                alpha=0.3, color='green', label='Uncertainty (±2σ)')\n",
    "ax.axvspan(-1.5, -0.5, alpha=0.1, color='red')\n",
    "ax.axvspan(0.5, 1.5, alpha=0.1, color='red')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_title('Bayesian Neural Network Predictions')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Training loss comparison\n",
    "ax = axes[1, 0]\n",
    "ax.plot(mc_losses, label='MC Dropout', alpha=0.7)\n",
    "ax.plot(bnn_losses, label='Bayesian NN', alpha=0.7)\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_title('Training Loss Comparison')\n",
    "ax.set_yscale('log')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Uncertainty comparison\n",
    "ax = axes[1, 1]\n",
    "ax.plot(x, std_pred, 'b-', label='MC Dropout', linewidth=2)\n",
    "ax.plot(x, std_bnn, 'g-', label='Bayesian NN', linewidth=2)\n",
    "ax.axvspan(-1.5, -0.5, alpha=0.1, color='red')\n",
    "ax.axvspan(0.5, 1.5, alpha=0.1, color='red')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('Uncertainty (σ)')\n",
    "ax.set_title('Uncertainty Comparison')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Deep Ensembles\n",
    "\n",
    "Deep ensembles train multiple models independently and combine their predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    \"\"\"Simple neural network for ensemble\"\"\"\n",
    "    def __init__(self, input_dim=1, hidden_dim=50, output_dim=1):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        # Different initialization for diversity\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class DeepEnsemble:\n",
    "    \"\"\"Deep ensemble for uncertainty estimation\"\"\"\n",
    "    def __init__(self, n_models=5, **model_kwargs):\n",
    "        self.n_models = n_models\n",
    "        self.models = [SimpleNN(**model_kwargs).to(device) for _ in range(n_models)]\n",
    "        \n",
    "    def train(self, x_train, y_train, epochs=1500):\n",
    "        \"\"\"Train ensemble members independently\"\"\"\n",
    "        x_tensor = torch.FloatTensor(x_train).unsqueeze(1).to(device)\n",
    "        y_tensor = torch.FloatTensor(y_train).unsqueeze(1).to(device)\n",
    "        \n",
    "        all_losses = []\n",
    "        \n",
    "        for i, model in enumerate(self.models):\n",
    "            print(f\"\\nTraining model {i+1}/{self.n_models}\")\n",
    "            optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "            scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=100)\n",
    "            \n",
    "            losses = []\n",
    "            \n",
    "            for epoch in range(epochs):\n",
    "                model.train()\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Add different random seeds for diversity\n",
    "                torch.manual_seed(42 + i * 1000 + epoch)\n",
    "                \n",
    "                output = model(x_tensor)\n",
    "                loss = F.mse_loss(output, y_tensor)\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                scheduler.step(loss)\n",
    "                \n",
    "                losses.append(loss.item())\n",
    "                \n",
    "                if epoch % 500 == 0:\n",
    "                    print(f\"  Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
    "            \n",
    "            all_losses.append(losses)\n",
    "        \n",
    "        return all_losses\n",
    "    \n",
    "    def predict_with_uncertainty(self, x):\n",
    "        \"\"\"Make predictions with uncertainty using ensemble\"\"\"\n",
    "        predictions = []\n",
    "        \n",
    "        for model in self.models:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                pred = model(x)\n",
    "                predictions.append(pred)\n",
    "        \n",
    "        predictions = torch.stack(predictions)\n",
    "        mean = predictions.mean(dim=0)\n",
    "        \n",
    "        # Total uncertainty from ensemble variance\n",
    "        epistemic_std = predictions.std(dim=0)\n",
    "        \n",
    "        return mean, epistemic_std, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train deep ensemble\n",
    "print(\"Training Deep Ensemble...\")\n",
    "ensemble = DeepEnsemble(n_models=5)\n",
    "ensemble_losses = ensemble.train(x_epistemic, y_epistemic)\n",
    "\n",
    "# Make predictions\n",
    "mean_ensemble, std_ensemble, ensemble_preds = ensemble.predict_with_uncertainty(x_test)\n",
    "mean_ensemble = mean_ensemble.cpu().numpy().flatten()\n",
    "std_ensemble = std_ensemble.cpu().numpy().flatten()\n",
    "ensemble_preds = ensemble_preds.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Comparison of Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive comparison visualization\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "# All methods comparison\n",
    "ax = axes[0, 0]\n",
    "ax.plot(x, y_true, 'k-', label='True function', linewidth=3)\n",
    "ax.scatter(x_epistemic[::3], y_epistemic[::3], alpha=0.3, s=20, color='gray', label='Training data')\n",
    "\n",
    "methods = [\n",
    "    ('MC Dropout', mean_pred, std_pred, 'blue'),\n",
    "    ('Bayesian NN', mean_bnn, std_bnn, 'green'),\n",
    "    ('Deep Ensemble', mean_ensemble, std_ensemble, 'red')\n",
    "]\n",
    "\n",
    "for name, mean, std, color in methods:\n",
    "    ax.plot(x, mean, color=color, label=f'{name}', linewidth=2, alpha=0.8)\n",
    "\n",
    "ax.axvspan(-1.5, -0.5, alpha=0.1, color='red')\n",
    "ax.axvspan(0.5, 1.5, alpha=0.1, color='red')\n",
    "ax.set_xlabel('x', fontsize=12)\n",
    "ax.set_ylabel('y', fontsize=12)\n",
    "ax.set_title('Method Comparison - Predictions', fontsize=14)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Uncertainty comparison\n",
    "ax = axes[0, 1]\n",
    "for name, _, std, color in methods:\n",
    "    ax.plot(x, std, color=color, label=name, linewidth=2)\n",
    "\n",
    "ax.axvspan(-1.5, -0.5, alpha=0.1, color='red')\n",
    "ax.axvspan(0.5, 1.5, alpha=0.1, color='red')\n",
    "ax.set_xlabel('x', fontsize=12)\n",
    "ax.set_ylabel('Uncertainty (σ)', fontsize=12)\n",
    "ax.set_title('Uncertainty Estimates', fontsize=14)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Bar plot of uncertainty ratios\n",
    "ax = axes[0, 2]\n",
    "uncertainty_ratios = []\n",
    "method_names = []\n",
    "\n",
    "for name, _, std, _ in methods:\n",
    "    ratio = std[no_data_regions].mean() / std[data_regions].mean()\n",
    "    uncertainty_ratios.append(ratio)\n",
    "    method_names.append(name)\n",
    "\n",
    "bars = ax.bar(method_names, uncertainty_ratios, color=['blue', 'green', 'red'], alpha=0.7)\n",
    "ax.axhline(y=1, color='black', linestyle='--', alpha=0.5)\n",
    "ax.set_ylabel('Uncertainty Ratio\\n(No Data / Data)', fontsize=12)\n",
    "ax.set_title('Epistemic Uncertainty Detection', fontsize=14)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, ratio in zip(bars, uncertainty_ratios):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n",
    "            f'{ratio:.2f}', ha='center', va='bottom')\n",
    "\n",
    "# Individual prediction samples\n",
    "for idx, (name, mean, std, color, preds) in enumerate([\n",
    "    ('MC Dropout', mean_pred, std_pred, 'blue', all_preds),\n",
    "    ('Bayesian NN', mean_bnn, std_bnn, 'green', None),\n",
    "    ('Deep Ensemble', mean_ensemble, std_ensemble, 'red', ensemble_preds)\n",
    "]):\n",
    "    ax = axes[1, idx]\n",
    "    ax.plot(x, y_true, 'k-', linewidth=2, alpha=0.5)\n",
    "    ax.scatter(x_epistemic[::3], y_epistemic[::3], alpha=0.3, s=20, color='gray')\n",
    "    \n",
    "    if preds is not None and name != 'Bayesian NN':\n",
    "        # Plot individual predictions\n",
    "        n_samples = min(20, preds.shape[0])\n",
    "        for i in range(n_samples):\n",
    "            if name == 'MC Dropout':\n",
    "                ax.plot(x, preds[i, :, 0], color=color, alpha=0.1, linewidth=0.5)\n",
    "            else:  # Deep Ensemble\n",
    "                ax.plot(x, preds[i, :, 0], color=color, alpha=0.3, linewidth=1)\n",
    "    \n",
    "    ax.plot(x, mean, color=color, linewidth=2, label='Mean')\n",
    "    ax.fill_between(x, mean - 2*std, mean + 2*std, color=color, alpha=0.2)\n",
    "    \n",
    "    ax.axvspan(-1.5, -0.5, alpha=0.1, color='red')\n",
    "    ax.axvspan(0.5, 1.5, alpha=0.1, color='red')\n",
    "    ax.set_xlabel('x', fontsize=12)\n",
    "    ax.set_ylabel('y', fontsize=12)\n",
    "    ax.set_title(f'{name} - Individual Predictions', fontsize=12)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Out-of-Distribution Detection\n",
    "\n",
    "A key application of uncertainty estimation is detecting out-of-distribution (OOD) data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate out-of-distribution data\n",
    "x_ood = np.linspace(4, 6, 50)\n",
    "x_ood_tensor = torch.FloatTensor(x_ood).unsqueeze(1).to(device)\n",
    "\n",
    "# Get predictions for OOD data\n",
    "ood_results = {}\n",
    "\n",
    "# MC Dropout\n",
    "mean_mc_ood, std_mc_ood, _ = mc_model.predict_with_uncertainty(x_ood_tensor)\n",
    "ood_results['MC Dropout'] = (mean_mc_ood.cpu().numpy().flatten(), \n",
    "                             std_mc_ood.cpu().numpy().flatten())\n",
    "\n",
    "# Bayesian NN\n",
    "mean_bnn_ood, std_bnn_ood, _ = bnn_model.predict_with_uncertainty(x_ood_tensor)\n",
    "ood_results['Bayesian NN'] = (mean_bnn_ood.cpu().numpy().flatten(),\n",
    "                              std_bnn_ood.cpu().numpy().flatten())\n",
    "\n",
    "# Deep Ensemble\n",
    "mean_ens_ood, std_ens_ood, _ = ensemble.predict_with_uncertainty(x_ood_tensor)\n",
    "ood_results['Deep Ensemble'] = (mean_ens_ood.cpu().numpy().flatten(),\n",
    "                                std_ens_ood.cpu().numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize OOD detection\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Predictions including OOD region\n",
    "ax = axes[0]\n",
    "x_full = np.concatenate([x, x_ood])\n",
    "\n",
    "# Training data region\n",
    "ax.axvspan(x_epistemic.min(), x_epistemic.max(), alpha=0.1, color='green', \n",
    "           label='Training data region')\n",
    "ax.axvspan(x_ood.min(), x_ood.max(), alpha=0.1, color='red',\n",
    "           label='OOD region')\n",
    "\n",
    "for (name, mean, std, color), (_, (mean_ood, std_ood)) in zip(methods, ood_results.items()):\n",
    "    mean_full = np.concatenate([mean, mean_ood])\n",
    "    ax.plot(x_full, mean_full, color=color, label=name, linewidth=2)\n",
    "\n",
    "ax.set_xlabel('x', fontsize=12)\n",
    "ax.set_ylabel('y', fontsize=12)\n",
    "ax.set_title('Predictions with OOD Region', fontsize=14)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Uncertainty for OOD detection\n",
    "ax = axes[1]\n",
    "ax.axvspan(x_epistemic.min(), x_epistemic.max(), alpha=0.1, color='green')\n",
    "ax.axvspan(x_ood.min(), x_ood.max(), alpha=0.1, color='red')\n",
    "\n",
    "for (name, _, std, color), (_, (_, std_ood)) in zip(methods, ood_results.items()):\n",
    "    std_full = np.concatenate([std, std_ood])\n",
    "    ax.plot(x_full, std_full, color=color, label=name, linewidth=2)\n",
    "\n",
    "ax.set_xlabel('x', fontsize=12)\n",
    "ax.set_ylabel('Uncertainty (σ)', fontsize=12)\n",
    "ax.set_title('Uncertainty-based OOD Detection', fontsize=14)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate OOD detection metrics\n",
    "print(\"OOD Detection Performance:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for name, (_, std), (_, (_, std_ood)) in zip([m[0] for m in methods], \n",
    "                                              [m[1:3] for m in methods],\n",
    "                                              ood_results.items()):\n",
    "    # Use 95th percentile of in-distribution uncertainty as threshold\n",
    "    threshold = np.percentile(std, 95)\n",
    "    ood_detected = np.mean(std_ood > threshold)\n",
    "    \n",
    "    # Average uncertainty increase\n",
    "    unc_increase = std_ood.mean() / std.mean()\n",
    "    \n",
    "    print(f\"{name:15} - OOD detection rate: {ood_detected:6.2%}, \"\n",
    "          f\"Uncertainty increase: {unc_increase:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Uncertainty Calibration\n",
    "\n",
    "Well-calibrated uncertainties mean that the predicted confidence matches the actual accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate calibration\n",
    "def plot_calibration(predictions, uncertainties, true_values, name, ax):\n",
    "    \"\"\"Plot calibration of uncertainty estimates\"\"\"\n",
    "    # Calculate errors\n",
    "    errors = np.abs(predictions - true_values)\n",
    "    \n",
    "    # Create calibration plot\n",
    "    ax.scatter(uncertainties, errors, alpha=0.5, s=20)\n",
    "    \n",
    "    # Perfect calibration lines\n",
    "    max_unc = uncertainties.max()\n",
    "    ax.plot([0, max_unc], [0, max_unc], 'r--', label='σ calibration', linewidth=2)\n",
    "    ax.plot([0, max_unc], [0, 2*max_unc], 'r:', label='2σ calibration', linewidth=1)\n",
    "    \n",
    "    # Calculate coverage\n",
    "    within_1sigma = np.mean(errors <= uncertainties)\n",
    "    within_2sigma = np.mean(errors <= 2*uncertainties)\n",
    "    \n",
    "    ax.set_xlabel('Predicted Uncertainty (σ)')\n",
    "    ax.set_ylabel('Actual Error')\n",
    "    ax.set_title(f'{name}\\n1σ: {within_1sigma:.1%}, 2σ: {within_2sigma:.1%}')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    return within_1sigma, within_2sigma\n",
    "\n",
    "# Create calibration plots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "calibration_results = []\n",
    "y_test_true = np.sin(x) + 0.3 * np.cos(2 * x)\n",
    "\n",
    "for idx, (name, mean, std, _) in enumerate(methods):\n",
    "    coverage_1s, coverage_2s = plot_calibration(mean, std, y_test_true, name, axes[idx])\n",
    "    calibration_results.append((name, coverage_1s, coverage_2s))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print calibration summary\n",
    "print(\"Calibration Summary:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Method':15} {'1σ Coverage':>15} {'2σ Coverage':>15} {'Status':>15}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for name, cov_1s, cov_2s in calibration_results:\n",
    "    # Expected: ~68.3% for 1σ, ~95.4% for 2σ\n",
    "    status = \"Well-calibrated\" if abs(cov_1s - 0.683) < 0.1 else \"Miscalibrated\"\n",
    "    print(f\"{name:15} {cov_1s:14.1%} {cov_2s:14.1%} {status:>15}\")\n",
    "\n",
    "print(\"\\nExpected:        68.3%          95.4%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary and Best Practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary comparison table\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "\n",
    "# Method comparison data\n",
    "comparison_data = [\n",
    "    ['Method', 'Computational Cost', 'Implementation', 'Uncertainty Quality', 'Best Use Case'],\n",
    "    ['MC Dropout', 'Low', 'Easy', 'Good', 'Quick uncertainty estimates'],\n",
    "    ['Bayesian NN', 'Medium', 'Complex', 'Excellent', 'When accuracy is critical'],\n",
    "    ['Deep Ensemble', 'High', 'Simple', 'Excellent', 'Best empirical performance'],\n",
    "]\n",
    "\n",
    "# Create table\n",
    "table = ax.table(cellText=comparison_data[1:], colLabels=comparison_data[0],\n",
    "                cellLoc='center', loc='center')\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(11)\n",
    "table.scale(1.2, 2)\n",
    "\n",
    "# Style the table\n",
    "for i in range(len(comparison_data[0])):\n",
    "    table[(0, i)].set_facecolor('#4CAF50')\n",
    "    table[(0, i)].set_text_props(weight='bold', color='white')\n",
    "\n",
    "# Color code rows\n",
    "colors = ['#E3F2FD', '#F3E5F5', '#FFEBEE']\n",
    "for i in range(1, len(comparison_data)):\n",
    "    for j in range(len(comparison_data[0])):\n",
    "        table[(i, j)].set_facecolor(colors[i-1])\n",
    "\n",
    "ax.set_title('Bayesian Deep Learning Methods Comparison', fontsize=16, pad=20)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Takeaways:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"1. Uncertainty quantification is crucial for reliable AI systems\")\n",
    "print(\"2. Different methods have different trade-offs\")\n",
    "print(\"3. MC Dropout: Easy to implement, good for most applications\")\n",
    "print(\"4. Bayesian NN: Principled approach, best theoretical foundation\")\n",
    "print(\"5. Deep Ensembles: Often best empirical performance\")\n",
    "print(\"6. Always validate uncertainty estimates on your specific problem\")\n",
    "print(\"7. Consider computational constraints when choosing a method\")\n",
    "print(\"\\nApplications: Medical AI, autonomous driving, financial modeling,\")\n",
    "print(\"              scientific discovery, and any safety-critical system.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
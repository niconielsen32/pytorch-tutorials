{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 18: Meta-Learning and Few-Shot Learning\n",
    "\n",
    "This tutorial explores meta-learning (learning to learn) and few-shot learning techniques, including MAML, Prototypical Networks, and Matching Networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from typing import Tuple, List, Dict\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "import copy\n",
    "import random\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Understanding Few-Shot Learning\n",
    "\n",
    "Few-shot learning aims to learn from very few examples. Let's visualize what a few-shot task looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic few-shot task\n",
    "def generate_task(n_way=5, k_shot=5, q_queries=15, feature_dim=100, noise_level=0.3):\n",
    "    \"\"\"Generate a synthetic N-way K-shot task\"\"\"\n",
    "    # Generate class prototypes\n",
    "    prototypes = torch.randn(n_way, feature_dim) * 2\n",
    "    \n",
    "    support_set = []\n",
    "    support_labels = []\n",
    "    query_set = []\n",
    "    query_labels = []\n",
    "    \n",
    "    for class_idx in range(n_way):\n",
    "        # Support set (few examples per class)\n",
    "        class_samples = prototypes[class_idx] + noise_level * torch.randn(k_shot, feature_dim)\n",
    "        support_set.append(class_samples)\n",
    "        support_labels.extend([class_idx] * k_shot)\n",
    "        \n",
    "        # Query set (examples to classify)\n",
    "        class_queries = prototypes[class_idx] + noise_level * torch.randn(q_queries, feature_dim)\n",
    "        query_set.append(class_queries)\n",
    "        query_labels.extend([class_idx] * q_queries)\n",
    "    \n",
    "    support_set = torch.cat(support_set, dim=0)\n",
    "    query_set = torch.cat(query_set, dim=0)\n",
    "    support_labels = torch.tensor(support_labels)\n",
    "    query_labels = torch.tensor(query_labels)\n",
    "    \n",
    "    # Shuffle\n",
    "    support_perm = torch.randperm(len(support_labels))\n",
    "    query_perm = torch.randperm(len(query_labels))\n",
    "    \n",
    "    return (support_set[support_perm], support_labels[support_perm],\n",
    "            query_set[query_perm], query_labels[query_perm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a few-shot task in 2D\n",
    "support_x, support_y, query_x, query_y = generate_task(n_way=3, k_shot=5, q_queries=10, feature_dim=2)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Colors and markers for different classes\n",
    "colors = ['#e74c3c', '#3498db', '#2ecc71', '#f39c12', '#9b59b6']\n",
    "markers = ['o', 's', '^', 'D', 'v']\n",
    "\n",
    "# Plot support and query sets\n",
    "for ax, title in [(ax1, 'Few-Shot Task Visualization'), (ax2, 'Task Structure')]:\n",
    "    for class_idx in range(3):\n",
    "        # Support set\n",
    "        support_mask = support_y == class_idx\n",
    "        ax.scatter(support_x[support_mask, 0], support_x[support_mask, 1], \n",
    "                  c=colors[class_idx], marker=markers[class_idx], s=150, \n",
    "                  label=f'Class {class_idx} (support)', edgecolors='black', linewidth=2)\n",
    "        \n",
    "        # Query set\n",
    "        query_mask = query_y == class_idx\n",
    "        ax.scatter(query_x[query_mask, 0], query_x[query_mask, 1], \n",
    "                  c=colors[class_idx], marker=markers[class_idx], s=80, \n",
    "                  label=f'Class {class_idx} (query)', alpha=0.5, edgecolors='gray')\n",
    "    \n",
    "    ax.set_xlabel('Feature 1', fontsize=12)\n",
    "    ax.set_ylabel('Feature 2', fontsize=12)\n",
    "    ax.set_title(title, fontsize=14)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Task structure explanation\n",
    "ax2.text(0.5, 0.95, '3-way 5-shot Learning Task', \n",
    "         transform=ax2.transAxes, ha='center', fontsize=16, fontweight='bold')\n",
    "ax2.text(0.5, 0.85, '• 3-way: 3 classes', transform=ax2.transAxes, ha='center', fontsize=12)\n",
    "ax2.text(0.5, 0.75, '• 5-shot: 5 examples per class in support set', \n",
    "         transform=ax2.transAxes, ha='center', fontsize=12)\n",
    "ax2.text(0.5, 0.65, '• Goal: Classify query examples using support set', \n",
    "         transform=ax2.transAxes, ha='center', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Few-shot Learning Task:\")\n",
    "print(f\"Support set: {support_x.shape[0]} examples ({support_x.shape[0]//3} per class)\")\n",
    "print(f\"Query set: {query_x.shape[0]} examples to classify\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model-Agnostic Meta-Learning (MAML)\n",
    "\n",
    "MAML learns an initialization that can be quickly fine-tuned to new tasks with just a few gradient steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleClassifier(nn.Module):\n",
    "    \"\"\"Simple neural network for few-shot classification\"\"\"\n",
    "    def __init__(self, input_size=84*84*3, hidden_size=128, output_size=5):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.classifier = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        features = self.features(x)\n",
    "        out = self.classifier(features)\n",
    "        return out, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MAML:\n",
    "    \"\"\"Model-Agnostic Meta-Learning implementation\"\"\"\n",
    "    def __init__(self, model, inner_lr=0.01, meta_lr=0.001, inner_steps=5):\n",
    "        self.model = model\n",
    "        self.inner_lr = inner_lr\n",
    "        self.meta_lr = meta_lr\n",
    "        self.inner_steps = inner_steps\n",
    "        self.meta_optimizer = optim.Adam(self.model.parameters(), lr=meta_lr)\n",
    "        \n",
    "    def inner_loop(self, support_x, support_y, fast_weights=None):\n",
    "        \"\"\"Inner loop adaptation on support set\"\"\"\n",
    "        if fast_weights is None:\n",
    "            fast_weights = OrderedDict(self.model.named_parameters())\n",
    "        \n",
    "        # Track adaptation path\n",
    "        adaptation_losses = []\n",
    "        \n",
    "        for step in range(self.inner_steps):\n",
    "            # Forward pass with fast weights\n",
    "            logits = self.functional_forward(support_x, fast_weights)\n",
    "            loss = F.cross_entropy(logits, support_y)\n",
    "            adaptation_losses.append(loss.item())\n",
    "            \n",
    "            # Compute gradients\n",
    "            grads = torch.autograd.grad(loss, fast_weights.values(), create_graph=True)\n",
    "            \n",
    "            # Update fast weights\n",
    "            fast_weights = OrderedDict(\n",
    "                (name, param - self.inner_lr * grad)\n",
    "                for (name, param), grad in zip(fast_weights.items(), grads)\n",
    "            )\n",
    "        \n",
    "        return fast_weights, adaptation_losses\n",
    "    \n",
    "    def functional_forward(self, x, params):\n",
    "        \"\"\"Forward pass using provided parameters\"\"\"\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Manually apply layers with given parameters\n",
    "        x = F.linear(x, params['features.0.weight'], params['features.0.bias'])\n",
    "        x = F.relu(x)\n",
    "        x = F.linear(x, params['features.2.weight'], params['features.2.bias'])\n",
    "        x = F.relu(x)\n",
    "        x = F.linear(x, params['classifier.weight'], params['classifier.bias'])\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def meta_train_step(self, tasks):\n",
    "        \"\"\"Meta-training step on batch of tasks\"\"\"\n",
    "        meta_loss = 0\n",
    "        task_accuracies = []\n",
    "        \n",
    "        for support_x, support_y, query_x, query_y in tasks:\n",
    "            # Inner loop adaptation\n",
    "            fast_weights, _ = self.inner_loop(support_x, support_y)\n",
    "            \n",
    "            # Evaluate on query set\n",
    "            query_logits = self.functional_forward(query_x, fast_weights)\n",
    "            query_loss = F.cross_entropy(query_logits, query_y)\n",
    "            \n",
    "            # Track accuracy\n",
    "            with torch.no_grad():\n",
    "                accuracy = (query_logits.argmax(dim=1) == query_y).float().mean()\n",
    "                task_accuracies.append(accuracy.item())\n",
    "            \n",
    "            meta_loss += query_loss\n",
    "        \n",
    "        # Meta-update\n",
    "        meta_loss = meta_loss / len(tasks)\n",
    "        self.meta_optimizer.zero_grad()\n",
    "        meta_loss.backward()\n",
    "        self.meta_optimizer.step()\n",
    "        \n",
    "        return meta_loss.item(), np.mean(task_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train MAML\n",
    "input_size = 100\n",
    "maml_model = SimpleClassifier(input_size=input_size, output_size=5).to(device)\n",
    "maml = MAML(maml_model, inner_lr=0.01, meta_lr=0.001, inner_steps=5)\n",
    "\n",
    "# Training loop\n",
    "meta_losses = []\n",
    "meta_accuracies = []\n",
    "\n",
    "print(\"Training MAML...\")\n",
    "for episode in range(200):\n",
    "    # Generate batch of tasks\n",
    "    tasks = []\n",
    "    for _ in range(4):  # 4 tasks per meta-batch\n",
    "        task = generate_task(n_way=5, k_shot=5, q_queries=15, feature_dim=input_size)\n",
    "        tasks.append([t.to(device) for t in task])\n",
    "    \n",
    "    # Meta-train step\n",
    "    loss, accuracy = maml.meta_train_step(tasks)\n",
    "    meta_losses.append(loss)\n",
    "    meta_accuracies.append(accuracy)\n",
    "    \n",
    "    if episode % 40 == 0:\n",
    "        print(f\"Episode {episode}, Meta Loss: {loss:.4f}, Meta Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize MAML adaptation process\n",
    "# Generate a new task and show adaptation\n",
    "test_task = generate_task(n_way=5, k_shot=5, q_queries=15, feature_dim=input_size)\n",
    "support_x, support_y, query_x, query_y = [t.to(device) for t in test_task]\n",
    "\n",
    "# Track adaptation\n",
    "adaptation_steps = 10\n",
    "fast_weights = OrderedDict(maml.model.named_parameters())\n",
    "adaptation_losses = []\n",
    "adaptation_accuracies = []\n",
    "\n",
    "for step in range(adaptation_steps):\n",
    "    # Evaluate current performance\n",
    "    with torch.no_grad():\n",
    "        query_logits = maml.functional_forward(query_x, fast_weights)\n",
    "        accuracy = (query_logits.argmax(dim=1) == query_y).float().mean()\n",
    "        adaptation_accuracies.append(accuracy.item())\n",
    "    \n",
    "    # Adaptation step\n",
    "    support_logits = maml.functional_forward(support_x, fast_weights)\n",
    "    loss = F.cross_entropy(support_logits, support_y)\n",
    "    adaptation_losses.append(loss.item())\n",
    "    \n",
    "    # Update\n",
    "    grads = torch.autograd.grad(loss, fast_weights.values())\n",
    "    fast_weights = OrderedDict(\n",
    "        (name, param - maml.inner_lr * grad)\n",
    "        for (name, param), grad in zip(fast_weights.items(), grads)\n",
    "    )\n",
    "\n",
    "# Plot adaptation\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "ax1.plot(adaptation_losses, 'o-', linewidth=2, markersize=8)\n",
    "ax1.set_xlabel('Adaptation Step')\n",
    "ax1.set_ylabel('Support Set Loss')\n",
    "ax1.set_title('MAML Adaptation: Loss')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.plot(adaptation_accuracies, 'o-', linewidth=2, markersize=8, color='green')\n",
    "ax2.set_xlabel('Adaptation Step')\n",
    "ax2.set_ylabel('Query Set Accuracy')\n",
    "ax2.set_title('MAML Adaptation: Accuracy')\n",
    "ax2.set_ylim(0, 1)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Initial accuracy: {adaptation_accuracies[0]:.2%}\")\n",
    "print(f\"Final accuracy: {adaptation_accuracies[-1]:.2%}\")\n",
    "print(f\"Improvement: {adaptation_accuracies[-1] - adaptation_accuracies[0]:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prototypical Networks\n",
    "\n",
    "Prototypical Networks learn an embedding space where classification is performed by finding the nearest class prototype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrototypicalNetwork(nn.Module):\n",
    "    \"\"\"Prototypical Networks for few-shot classification\"\"\"\n",
    "    def __init__(self, input_size, hidden_size=128, embedding_size=64):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, embedding_size)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.encoder(x)\n",
    "    \n",
    "    def compute_prototypes(self, support_embeddings, support_labels, n_way):\n",
    "        \"\"\"Compute class prototypes from support set\"\"\"\n",
    "        prototypes = torch.zeros(n_way, support_embeddings.size(1)).to(support_embeddings.device)\n",
    "        \n",
    "        for class_idx in range(n_way):\n",
    "            mask = support_labels == class_idx\n",
    "            class_embeddings = support_embeddings[mask]\n",
    "            prototypes[class_idx] = class_embeddings.mean(dim=0)\n",
    "        \n",
    "        return prototypes\n",
    "    \n",
    "    def prototypical_loss(self, prototypes, query_embeddings, query_labels):\n",
    "        \"\"\"Compute prototypical loss\"\"\"\n",
    "        # Compute distances from queries to prototypes\n",
    "        distances = torch.cdist(query_embeddings, prototypes)\n",
    "        \n",
    "        # Convert to similarities (negative distance)\n",
    "        log_p_y = F.log_softmax(-distances, dim=1)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = F.nll_loss(log_p_y, query_labels)\n",
    "        \n",
    "        # Compute accuracy\n",
    "        predictions = (-distances).argmax(dim=1)\n",
    "        accuracy = (predictions == query_labels).float().mean()\n",
    "        \n",
    "        return loss, accuracy, distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Prototypical Network\n",
    "proto_net = PrototypicalNetwork(input_size=100, embedding_size=64).to(device)\n",
    "optimizer = optim.Adam(proto_net.parameters(), lr=0.001)\n",
    "\n",
    "proto_losses = []\n",
    "proto_accuracies = []\n",
    "\n",
    "print(\"Training Prototypical Network...\")\n",
    "for episode in range(300):\n",
    "    # Generate task\n",
    "    support_x, support_y, query_x, query_y = generate_task(\n",
    "        n_way=5, k_shot=5, q_queries=15, feature_dim=100\n",
    "    )\n",
    "    \n",
    "    support_x = support_x.to(device)\n",
    "    support_y = support_y.to(device)\n",
    "    query_x = query_x.to(device)\n",
    "    query_y = query_y.to(device)\n",
    "    \n",
    "    # Forward pass\n",
    "    support_embeddings = proto_net(support_x)\n",
    "    query_embeddings = proto_net(query_x)\n",
    "    \n",
    "    # Compute prototypes\n",
    "    prototypes = proto_net.compute_prototypes(support_embeddings, support_y, n_way=5)\n",
    "    \n",
    "    # Compute loss\n",
    "    loss, accuracy, _ = proto_net.prototypical_loss(prototypes, query_embeddings, query_y)\n",
    "    \n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    proto_losses.append(loss.item())\n",
    "    proto_accuracies.append(accuracy.item())\n",
    "    \n",
    "    if episode % 60 == 0:\n",
    "        print(f\"Episode {episode}, Loss: {loss.item():.4f}, Accuracy: {accuracy.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize prototypical space\n",
    "# Generate a task and visualize embeddings\n",
    "test_task = generate_task(n_way=5, k_shot=5, q_queries=20, feature_dim=100)\n",
    "support_x, support_y, query_x, query_y = [t.to(device) for t in test_task]\n",
    "\n",
    "with torch.no_grad():\n",
    "    support_embeddings = proto_net(support_x)\n",
    "    query_embeddings = proto_net(query_x)\n",
    "    prototypes = proto_net.compute_prototypes(support_embeddings, support_y, n_way=5)\n",
    "\n",
    "# Combine all embeddings for t-SNE\n",
    "all_embeddings = torch.cat([support_embeddings, query_embeddings, prototypes], dim=0)\n",
    "all_embeddings_np = all_embeddings.cpu().numpy()\n",
    "\n",
    "# Apply t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "embeddings_2d = tsne.fit_transform(all_embeddings_np)\n",
    "\n",
    "# Split back\n",
    "n_support = len(support_y)\n",
    "n_query = len(query_y)\n",
    "support_2d = embeddings_2d[:n_support]\n",
    "query_2d = embeddings_2d[n_support:n_support+n_query]\n",
    "prototypes_2d = embeddings_2d[n_support+n_query:]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors = ['#e74c3c', '#3498db', '#2ecc71', '#f39c12', '#9b59b6']\n",
    "\n",
    "for class_idx in range(5):\n",
    "    # Support points\n",
    "    support_mask = support_y.cpu() == class_idx\n",
    "    plt.scatter(support_2d[support_mask, 0], support_2d[support_mask, 1],\n",
    "               c=colors[class_idx], marker='o', s=100, alpha=0.6,\n",
    "               label=f'Class {class_idx} support')\n",
    "    \n",
    "    # Query points\n",
    "    query_mask = query_y.cpu() == class_idx\n",
    "    plt.scatter(query_2d[query_mask, 0], query_2d[query_mask, 1],\n",
    "               c=colors[class_idx], marker='x', s=100, alpha=0.8)\n",
    "    \n",
    "    # Prototype\n",
    "    plt.scatter(prototypes_2d[class_idx, 0], prototypes_2d[class_idx, 1],\n",
    "               c=colors[class_idx], marker='*', s=500, edgecolors='black', linewidth=2)\n",
    "\n",
    "plt.xlabel('t-SNE dimension 1')\n",
    "plt.ylabel('t-SNE dimension 2')\n",
    "plt.title('Prototypical Network Embedding Space (t-SNE visualization)')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Legend: ○ = support examples, × = query examples, ★ = prototypes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Matching Networks\n",
    "\n",
    "Matching Networks use attention mechanisms to compare query examples with the support set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatchingNetwork(nn.Module):\n",
    "    \"\"\"Matching Networks with attention mechanism\"\"\"\n",
    "    def __init__(self, input_size, hidden_size=128, embedding_size=64):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, embedding_size)\n",
    "        )\n",
    "        \n",
    "        # Bidirectional LSTM for full context embeddings\n",
    "        self.lstm = nn.LSTM(embedding_size, embedding_size, batch_first=True, bidirectional=True)\n",
    "        self.attention_fc = nn.Linear(embedding_size * 2, embedding_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.encoder(x)\n",
    "    \n",
    "    def attention(self, query, support, support_labels):\n",
    "        \"\"\"Compute attention-weighted predictions\"\"\"\n",
    "        # Compute cosine similarity\n",
    "        query_norm = F.normalize(query, p=2, dim=1)\n",
    "        support_norm = F.normalize(support, p=2, dim=1)\n",
    "        similarities = torch.mm(query_norm, support_norm.t())\n",
    "        \n",
    "        # Apply softmax to get attention weights\n",
    "        attention_weights = F.softmax(similarities, dim=1)\n",
    "        \n",
    "        # Convert labels to one-hot\n",
    "        n_way = support_labels.max().item() + 1\n",
    "        support_labels_onehot = F.one_hot(support_labels, n_way).float()\n",
    "        \n",
    "        # Weighted sum of support labels\n",
    "        predictions = torch.mm(attention_weights, support_labels_onehot)\n",
    "        \n",
    "        return predictions, attention_weights\n",
    "    \n",
    "    def full_context_embedding(self, embeddings):\n",
    "        \"\"\"Apply bidirectional LSTM for full context\"\"\"\n",
    "        # Add batch dimension if needed\n",
    "        if embeddings.dim() == 2:\n",
    "            embeddings = embeddings.unsqueeze(0)\n",
    "        \n",
    "        lstm_out, _ = self.lstm(embeddings)\n",
    "        lstm_out = self.attention_fc(lstm_out)\n",
    "        \n",
    "        return lstm_out.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Matching Network\n",
    "matching_net = MatchingNetwork(input_size=100).to(device)\n",
    "matching_optimizer = optim.Adam(matching_net.parameters(), lr=0.001)\n",
    "\n",
    "matching_losses = []\n",
    "matching_accuracies = []\n",
    "\n",
    "print(\"Training Matching Network...\")\n",
    "for episode in range(300):\n",
    "    # Generate task\n",
    "    support_x, support_y, query_x, query_y = generate_task(\n",
    "        n_way=5, k_shot=5, q_queries=15, feature_dim=100\n",
    "    )\n",
    "    \n",
    "    support_x = support_x.to(device)\n",
    "    support_y = support_y.to(device)\n",
    "    query_x = query_x.to(device)\n",
    "    query_y = query_y.to(device)\n",
    "    \n",
    "    # Get embeddings\n",
    "    support_embeddings = matching_net(support_x)\n",
    "    query_embeddings = matching_net(query_x)\n",
    "    \n",
    "    # Apply full context embedding\n",
    "    support_embeddings = matching_net.full_context_embedding(support_embeddings)\n",
    "    \n",
    "    # Get predictions using attention\n",
    "    predictions, attention_weights = matching_net.attention(\n",
    "        query_embeddings, support_embeddings, support_y\n",
    "    )\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = F.cross_entropy(predictions, query_y)\n",
    "    accuracy = (predictions.argmax(dim=1) == query_y).float().mean()\n",
    "    \n",
    "    # Backward pass\n",
    "    matching_optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    matching_optimizer.step()\n",
    "    \n",
    "    matching_losses.append(loss.item())\n",
    "    matching_accuracies.append(accuracy.item())\n",
    "    \n",
    "    if episode % 60 == 0:\n",
    "        print(f\"Episode {episode}, Loss: {loss.item():.4f}, Accuracy: {accuracy.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize attention mechanism\n",
    "# Generate a small task for visualization\n",
    "vis_task = generate_task(n_way=3, k_shot=3, q_queries=5, feature_dim=100)\n",
    "support_x, support_y, query_x, query_y = [t.to(device) for t in vis_task]\n",
    "\n",
    "with torch.no_grad():\n",
    "    support_embeddings = matching_net(support_x)\n",
    "    query_embeddings = matching_net(query_x)\n",
    "    support_embeddings = matching_net.full_context_embedding(support_embeddings)\n",
    "    predictions, attention_weights = matching_net.attention(\n",
    "        query_embeddings, support_embeddings, support_y\n",
    "    )\n",
    "\n",
    "# Plot attention heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(attention_weights.cpu().numpy(), \n",
    "            cmap='YlOrRd', \n",
    "            xticklabels=[f'S{i}\\n(C{support_y[i].item()})' for i in range(len(support_y))],\n",
    "            yticklabels=[f'Q{i}\\n(C{query_y[i].item()})' for i in range(len(query_y))],\n",
    "            annot=True, \n",
    "            fmt='.2f',\n",
    "            cbar_kws={'label': 'Attention Weight'})\n",
    "\n",
    "plt.xlabel('Support Examples', fontsize=12)\n",
    "plt.ylabel('Query Examples', fontsize=12)\n",
    "plt.title('Matching Network Attention Weights', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"S = Support, Q = Query, C = Class\")\n",
    "print(\"High attention weights indicate which support examples are most relevant for each query\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Algorithm Comparison\n",
    "\n",
    "Let's compare the performance and characteristics of different meta-learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# MAML\n",
    "axes[0, 0].plot(meta_losses, label='Loss', alpha=0.7)\n",
    "axes[0, 0].set_title('MAML Training', fontsize=14)\n",
    "axes[0, 0].set_xlabel('Episode')\n",
    "axes[0, 0].set_ylabel('Meta Loss')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 0].plot(meta_accuracies, label='Accuracy', alpha=0.7, color='green')\n",
    "axes[1, 0].set_title('MAML Accuracy', fontsize=14)\n",
    "axes[1, 0].set_xlabel('Episode')\n",
    "axes[1, 0].set_ylabel('Meta Accuracy')\n",
    "axes[1, 0].set_ylim(0, 1)\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Prototypical Networks\n",
    "axes[0, 1].plot(proto_losses, label='Loss', alpha=0.7, color='orange')\n",
    "axes[0, 1].set_title('Prototypical Networks Training', fontsize=14)\n",
    "axes[0, 1].set_xlabel('Episode')\n",
    "axes[0, 1].set_ylabel('Loss')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 1].plot(proto_accuracies, label='Accuracy', alpha=0.7, color='green')\n",
    "axes[1, 1].set_title('Prototypical Networks Accuracy', fontsize=14)\n",
    "axes[1, 1].set_xlabel('Episode')\n",
    "axes[1, 1].set_ylabel('Accuracy')\n",
    "axes[1, 1].set_ylim(0, 1)\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Matching Networks\n",
    "axes[0, 2].plot(matching_losses, label='Loss', alpha=0.7, color='purple')\n",
    "axes[0, 2].set_title('Matching Networks Training', fontsize=14)\n",
    "axes[0, 2].set_xlabel('Episode')\n",
    "axes[0, 2].set_ylabel('Loss')\n",
    "axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 2].plot(matching_accuracies, label='Accuracy', alpha=0.7, color='green')\n",
    "axes[1, 2].set_title('Matching Networks Accuracy', fontsize=14)\n",
    "axes[1, 2].set_xlabel('Episode')\n",
    "axes[1, 2].set_ylabel('Accuracy')\n",
    "axes[1, 2].set_ylim(0, 1)\n",
    "axes[1, 2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm comparison radar chart\n",
    "categories = ['Training\\nSpeed', 'Inference\\nSpeed', 'Memory\\nEfficiency', \n",
    "              'Adaptation\\nFlexibility', 'Implementation\\nSimplicity']\n",
    "\n",
    "# Scores (1-5 scale)\n",
    "algorithms = {\n",
    "    'MAML': [2, 3, 2, 5, 2],\n",
    "    'Prototypical': [5, 5, 5, 3, 5],\n",
    "    'Matching': [4, 4, 3, 4, 3],\n",
    "    'Reptile': [4, 3, 4, 4, 4]\n",
    "}\n",
    "\n",
    "# Create radar chart\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='polar')\n",
    "\n",
    "# Number of variables\n",
    "num_vars = len(categories)\n",
    "\n",
    "# Compute angle for each axis\n",
    "angles = [n / float(num_vars) * 2 * np.pi for n in range(num_vars)]\n",
    "angles += angles[:1]\n",
    "\n",
    "# Plot each algorithm\n",
    "colors = ['#e74c3c', '#3498db', '#2ecc71', '#f39c12']\n",
    "for idx, (algo, scores) in enumerate(algorithms.items()):\n",
    "    values = scores + scores[:1]\n",
    "    ax.plot(angles, values, 'o-', linewidth=2, label=algo, color=colors[idx])\n",
    "    ax.fill(angles, values, alpha=0.15, color=colors[idx])\n",
    "\n",
    "# Fix axis to go in the right order and start at 12 o'clock\n",
    "ax.set_theta_offset(np.pi / 2)\n",
    "ax.set_theta_direction(-1)\n",
    "\n",
    "# Draw axis lines for each angle and label\n",
    "ax.set_xticks(angles[:-1])\n",
    "ax.set_xticklabels(categories)\n",
    "\n",
    "# Set y-axis limits and labels\n",
    "ax.set_ylim(0, 5)\n",
    "ax.set_yticks([1, 2, 3, 4, 5])\n",
    "ax.set_yticklabels(['1', '2', '3', '4', '5'])\n",
    "\n",
    "# Add legend and title\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n",
    "plt.title('Meta-Learning Algorithm Comparison', size=16, y=1.08)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Practical Guidelines\n",
    "\n",
    "Let's summarize when to use each algorithm and best practices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create decision flowchart\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "ax.axis('off')\n",
    "\n",
    "# Title\n",
    "ax.text(0.5, 0.95, 'Meta-Learning Algorithm Selection Guide', \n",
    "        ha='center', fontsize=18, fontweight='bold')\n",
    "\n",
    "# Decision tree text\n",
    "decision_tree = \"\"\"\n",
    "Start: Do you need fast adaptation at test time?\n",
    "│\n",
    "├─ Yes → Do you have computational resources for second-order gradients?\n",
    "│   │\n",
    "│   ├─ Yes → Use MAML\n",
    "│   │        • Best for: Tasks requiring fine-tuning\n",
    "│   │        • Pros: Flexible, strong performance\n",
    "│   │        • Cons: Computationally expensive\n",
    "│   │\n",
    "│   └─ No → Use Reptile\n",
    "│            • Best for: Scalable meta-learning\n",
    "│            • Pros: Simple, efficient\n",
    "│            • Cons: Slightly worse than MAML\n",
    "│\n",
    "└─ No → Is your problem metric-based?\n",
    "    │\n",
    "    ├─ Yes → Do you need attention mechanisms?\n",
    "    │   │\n",
    "    │   ├─ Yes → Use Matching Networks\n",
    "    │   │        • Best for: Complex similarity measures\n",
    "    │   │        • Pros: Flexible comparisons\n",
    "    │   │        • Cons: More complex\n",
    "    │   │\n",
    "    │   └─ No → Use Prototypical Networks\n",
    "    │            • Best for: Simple classification\n",
    "    │            • Pros: Fast, simple, effective\n",
    "    │            • Cons: Less flexible\n",
    "    │\n",
    "    └─ Consider other approaches\n",
    "\"\"\"\n",
    "\n",
    "ax.text(0.1, 0.5, decision_tree, fontsize=11, family='monospace', \n",
    "        verticalalignment='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best practices summary\n",
    "print(\"Meta-Learning Best Practices\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "practices = [\n",
    "    (\"Task Construction\", [\n",
    "        \"Ensure meta-train and meta-test tasks come from same distribution\",\n",
    "        \"Use sufficient task diversity during training\",\n",
    "        \"Balance classes within each task\"\n",
    "    ]),\n",
    "    (\"Model Architecture\", [\n",
    "        \"Keep models relatively small for few-shot scenarios\",\n",
    "        \"Use appropriate embedding dimensions\",\n",
    "        \"Consider domain-specific architectures (CNN for images, etc.)\"\n",
    "    ]),\n",
    "    (\"Training Tips\", [\n",
    "        \"Use episodic training matching test conditions\",\n",
    "        \"Monitor both support and query set performance\",\n",
    "        \"Implement proper train/val/test splits at task level\"\n",
    "    ]),\n",
    "    (\"Hyperparameters\", [\n",
    "        \"Inner LR (MAML): typically 0.01-0.1\",\n",
    "        \"Outer LR: typically 0.001-0.003\",\n",
    "        \"Inner steps: 5-10 for most problems\"\n",
    "    ]),\n",
    "    (\"Evaluation\", [\n",
    "        \"Test on completely new classes/tasks\",\n",
    "        \"Report confidence intervals over multiple runs\",\n",
    "        \"Consider both mean and worst-case performance\"\n",
    "    ])\n",
    "]\n",
    "\n",
    "for category, tips in practices:\n",
    "    print(f\"\\n{category}:\")\n",
    "    for tip in tips:\n",
    "        print(f\"  • {tip}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Remember: The choice of algorithm depends heavily on your specific\")\n",
    "print(\"problem constraints and requirements!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, we explored meta-learning and few-shot learning:\n",
    "\n",
    "1. **MAML**: Learns an initialization for fast gradient-based adaptation\n",
    "2. **Prototypical Networks**: Uses class prototypes in embedding space\n",
    "3. **Matching Networks**: Employs attention mechanisms for classification\n",
    "4. **Key Concepts**: Task distributions, episodic training, fast adaptation\n",
    "\n",
    "### Key Takeaways:\n",
    "- Meta-learning enables learning from very few examples\n",
    "- Different algorithms suit different scenarios\n",
    "- Optimization-based (MAML) vs. metric-based (ProtoNet) approaches\n",
    "- Proper task construction is crucial\n",
    "- These techniques are vital for data-scarce domains\n",
    "\n",
    "Meta-learning is an active research area with applications in robotics, drug discovery, personalized systems, and more!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}